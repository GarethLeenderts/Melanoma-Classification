{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T12:55:54.809760Z","iopub.execute_input":"2021-08-04T12:55:54.810154Z","iopub.status.idle":"2021-08-04T12:55:54.819427Z","shell.execute_reply.started":"2021-08-04T12:55:54.810073Z","shell.execute_reply":"2021-08-04T12:55:54.818425Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Process\n\n* Set imports\n* Define model architecture\n* set device(GPU or CPU)\n* Define hyperparameters\n* Create your(custom) Dataset(inherits from the Dataset class)\n    * Define DataSets\n    * Define DataLoaders\n* initialize/instantiate network\n* Compile model\n    * Define loss\n    * Define optimizer\n* Train the network (create training for loop)\n    set model to training mode? model.train()?\n    * for epochs\n        * for batch, features, labels in DataLoader\n            * set data to the device(import for cuda, ie. gpu enabled)\n            * Forward pass: predictions and loss\n            * Backward pass: optimizer.zero_grad() & loss.backward()\n            * Gradient descent: optimizer.step()\n* Define testing/validation loop\n    * remember: set model to evaluation mode(with torch.zero_grad??? or model.eval()???)\n    \n\n* Data Augmentation (extra step for image data)\n    * Done with PyTorch Transforms\n    * `import torchvision.transforms as transforms`\n    * `my_transforms = transforms.Compose([your list of transformations go here])`\n    * tranforms get implemented in datasets when you include them in the `transforms` argument of the dataset","metadata":{}},{"cell_type":"code","source":"# imports\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom tqdm import tqdm  \nimport torchvision.transforms as transforms\n\nimport matplotlib.image as img\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:54.821353Z","iopub.execute_input":"2021-08-04T12:55:54.821733Z","iopub.status.idle":"2021-08-04T12:55:57.029196Z","shell.execute_reply.started":"2021-08-04T12:55:54.821701Z","shell.execute_reply":"2021-08-04T12:55:57.028370Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nlearning_rate = 0.001 #0.0003 #0.001\nbatch_size = 80 #80 #16 #32 #64","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:57.030850Z","iopub.execute_input":"2021-08-04T12:55:57.031212Z","iopub.status.idle":"2021-08-04T12:55:57.036106Z","shell.execute_reply.started":"2021-08-04T12:55:57.031178Z","shell.execute_reply":"2021-08-04T12:55:57.035225Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:57.037768Z","iopub.execute_input":"2021-08-04T12:55:57.038254Z","iopub.status.idle":"2021-08-04T12:55:57.119452Z","shell.execute_reply.started":"2021-08-04T12:55:57.038219Z","shell.execute_reply":"2021-08-04T12:55:57.118656Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:57.120581Z","iopub.execute_input":"2021-08-04T12:55:57.120946Z","iopub.status.idle":"2021-08-04T12:55:57.147431Z","shell.execute_reply.started":"2021-08-04T12:55:57.120912Z","shell.execute_reply":"2021-08-04T12:55:57.146618Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df = df[[\"image_name\",\"target\"]].sample(3000, random_state=125)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:57.148692Z","iopub.execute_input":"2021-08-04T12:55:57.149057Z","iopub.status.idle":"2021-08-04T12:55:57.153299Z","shell.execute_reply.started":"2021-08-04T12:55:57.149022Z","shell.execute_reply":"2021-08-04T12:55:57.152127Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# df[[\"image_name\",\"target\"]][df[\"target\"] == 1].info()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:57.156203Z","iopub.execute_input":"2021-08-04T12:55:57.156594Z","iopub.status.idle":"2021-08-04T12:55:57.161084Z","shell.execute_reply.started":"2021-08-04T12:55:57.156538Z","shell.execute_reply":"2021-08-04T12:55:57.160042Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Dataset\nclass Melanoma_Dataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.annotations = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        length = self.annotations.shape[0]\n        return length\n    \n    def __getitem__(self, idx):\n        image_name = self.annotations[\"image_name\"].iloc[idx]\n        target = self.annotations[\"target\"].iloc[idx]\n        image_path = self.root_dir + \"/\" + image_name + \".jpg\"\n        image = img.imread(image_path)\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        \n        target = torch.tensor([target], dtype=torch.float32)\n            \n        return image, target","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:57.163410Z","iopub.execute_input":"2021-08-04T12:55:57.163769Z","iopub.status.idle":"2021-08-04T12:55:57.174637Z","shell.execute_reply.started":"2021-08-04T12:55:57.163734Z","shell.execute_reply":"2021-08-04T12:55:57.173702Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#VGG16 model\n\n# base_model = torchvision.models.vgg16_bn(pretrained=True)\n# torch.save(base_model, \"./vgg16_bn.pt\") # saves to \"output\"\n\nbase_model = torch.load(\"../input/siimmelanomatrainedmodels/vgg16_bn.pt\")\n\n# print(base_model)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:55:57.176989Z","iopub.execute_input":"2021-08-04T12:55:57.177705Z","iopub.status.idle":"2021-08-04T12:56:01.947273Z","shell.execute_reply.started":"2021-08-04T12:55:57.177664Z","shell.execute_reply":"2021-08-04T12:56:01.946381Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# print(base_model)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:01.949397Z","iopub.execute_input":"2021-08-04T12:56:01.949738Z","iopub.status.idle":"2021-08-04T12:56:01.956267Z","shell.execute_reply.started":"2021-08-04T12:56:01.949713Z","shell.execute_reply":"2021-08-04T12:56:01.954465Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# print(base_model)\n\nclass VGG16_BatchNorm_base(nn.Module):\n    def __init__(self, base_trainable=False):\n        super(VGG16_BatchNorm_base, self).__init__()\n        \n        self.vgg16_base = base_model\n        \n        for param in self.vgg16_base.parameters():\n            param.requires_grad = base_trainable\n        \n        self.fc1 = nn.Linear(1000, 1000)\n        self.fc2 = nn.Linear(1000, 500)\n        self.fc3 = nn.Linear(500, 100)\n        self.fc4 = nn.Linear(100, 1)\n        \n    def forward(self, x):\n        x = self.vgg16_base(x)\n#         x1 = torch.sigmoid(self.fc1(x))\n#         x = torch.mul(x, x1)\n        x = torch.nn.functional.relu(self.fc1(x))\n        x = torch.nn.functional.relu(self.fc2(x))\n        x = torch.nn.functional.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:01.957781Z","iopub.execute_input":"2021-08-04T12:56:01.958286Z","iopub.status.idle":"2021-08-04T12:56:01.967248Z","shell.execute_reply.started":"2021-08-04T12:56:01.958249Z","shell.execute_reply":"2021-08-04T12:56:01.966296Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:01.968577Z","iopub.execute_input":"2021-08-04T12:56:01.969058Z","iopub.status.idle":"2021-08-04T12:56:02.038873Z","shell.execute_reply.started":"2021-08-04T12:56:01.969022Z","shell.execute_reply":"2021-08-04T12:56:02.038037Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# augmentations/transforms\nimages_mean = (0.8060590931711208, 0.620982283291032, 0.5915027590675953)\nimages_std = (0.08131081913267031, 0.09455098010432171, 0.10589780296354254)\nimage_transforms = transforms.Compose(\n    [  # Compose makes it possible to have many transforms\n        transforms.ToPILImage(),\n        transforms.RandomRotation(degrees=90),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=images_mean, std=images_std),\n    ]\n)\n\n\ntest_transforms = transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=images_mean, std=images_std),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:02.042083Z","iopub.execute_input":"2021-08-04T12:56:02.042408Z","iopub.status.idle":"2021-08-04T12:56:02.050921Z","shell.execute_reply.started":"2021-08-04T12:56:02.042383Z","shell.execute_reply":"2021-08-04T12:56:02.050137Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.1) #, random_state=125)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:02.054046Z","iopub.execute_input":"2021-08-04T12:56:02.054339Z","iopub.status.idle":"2021-08-04T12:56:02.073945Z","shell.execute_reply.started":"2021-08-04T12:56:02.054314Z","shell.execute_reply":"2021-08-04T12:56:02.073115Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"total_samples = len(train_df[\"target\"])\nclass_1_count = sum(train_df[\"target\"]) + 0.0001 #in case class_1_count is zero\nclass_0_count = total_samples - class_1_count\nclass_weights = [total_samples/class_0_count, total_samples/class_1_count]\n\nlist_of_weights = [class_weights[i] for i in train_df[\"target\"]]\nweighted_sampler = WeightedRandomSampler(list_of_weights, num_samples = len(list_of_weights), replacement=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:02.075080Z","iopub.execute_input":"2021-08-04T12:56:02.075408Z","iopub.status.idle":"2021-08-04T12:56:02.093761Z","shell.execute_reply.started":"2021-08-04T12:56:02.075374Z","shell.execute_reply":"2021-08-04T12:56:02.092865Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # Instantiate Datasets and DataLoaders\n# # root_directory = \"../input/siim-isic-melanoma-classification/jpeg/train\"\nroot_directory = \"../input/siimisic-resized-224x224-jpeg/output_train/train\"\n\ntrain_ds = Melanoma_Dataset(train_df, root_dir=root_directory, transform=image_transforms)\ntest_ds = Melanoma_Dataset(test_df, root_dir=root_directory, transform=image_transforms)\n\ntrain_loader = DataLoader(dataset=train_ds, batch_size=batch_size, sampler=weighted_sampler,\n                          num_workers=1, pin_memory=True) #, shuffle=False) shuffle synonymous with sampler\ntest_loader = DataLoader(dataset=test_ds, batch_size=batch_size, \n                         num_workers=1, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:02.096445Z","iopub.execute_input":"2021-08-04T12:56:02.096685Z","iopub.status.idle":"2021-08-04T12:56:02.101303Z","shell.execute_reply.started":"2021-08-04T12:56:02.096662Z","shell.execute_reply":"2021-08-04T12:56:02.100567Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Instantiate network\n\nmodel = VGG16_BatchNorm_base(base_trainable=True).to(device)\n\n# model_checkpoint = torch.load(\"./VGG16_bn_model_checkpoint_epoch_4.pt\", \n#                               map_location=device)\n# model_state_dict = model_checkpoint[\"model_state\"]\n# model.load_state_dict(model_state_dict)\n# model = model.to(device)\n\n\n\n# using a pretrained model state_dict\n# model_state_dict = torch.load(\"path-to-state_dict\", \n#                               map_location=device)\n# model.load_state_dict(model_state_dict)\n# model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:02.102481Z","iopub.execute_input":"2021-08-04T12:56:02.103045Z","iopub.status.idle":"2021-08-04T12:56:06.370684Z","shell.execute_reply.started":"2021-08-04T12:56:02.103009Z","shell.execute_reply":"2021-08-04T12:56:06.369868Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# print(model_checkpoint[\"scheduler_state\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.371938Z","iopub.execute_input":"2021-08-04T12:56:06.372322Z","iopub.status.idle":"2021-08-04T12:56:06.376452Z","shell.execute_reply.started":"2021-08-04T12:56:06.372284Z","shell.execute_reply":"2021-08-04T12:56:06.375653Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Focal Loss Function\n# from this blog post: https://amaarora.github.io/2020/06/29/FocalLoss.html\n\nclass WeightedFocalLoss(nn.Module):\n    \"Non weighted version of Focal Loss\"\n    def __init__(self, alpha=.25, gamma=2):\n        super(WeightedFocalLoss, self).__init__()\n        self.alpha = torch.tensor([alpha, 1-alpha]).to(device)  #.cuda() #remember to define \"device\"\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        targets = targets.type(torch.long)\n        at = self.alpha.gather(0, targets.data.view(-1))\n        pt = torch.exp(-BCE_loss)\n        F_loss = at*(1-pt)**self.gamma * BCE_loss\n        return F_loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.380216Z","iopub.execute_input":"2021-08-04T12:56:06.380767Z","iopub.status.idle":"2021-08-04T12:56:06.388861Z","shell.execute_reply.started":"2021-08-04T12:56:06.380730Z","shell.execute_reply":"2021-08-04T12:56:06.388051Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# class RMSLELoss(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.mse = nn.MSELoss()\n        \n#     def forward(self, pred, actual):\n#         return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.390803Z","iopub.execute_input":"2021-08-04T12:56:06.391175Z","iopub.status.idle":"2021-08-04T12:56:06.397628Z","shell.execute_reply.started":"2021-08-04T12:56:06.391125Z","shell.execute_reply":"2021-08-04T12:56:06.396824Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# # Loss and optimizer\n# # loss_function = nn.BCEWithLogitsLoss()\n# loss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\n# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# # learning rate scheduler\n# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate, \n#                                               max_lr=0.5,step_size_up=5,mode=\"triangular2\")\n\n# loss_function = nn.MSELoss()\n# loss_function = RMSLELoss()\n\nloss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\n\n# from abishek thakur: https://www.kaggle.com/abhishek/melanoma-detection-with-pytorch?scriptVersionId=35193166\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                       patience=3, \n                                                       threshold=0.001, \n                                                       mode=\"max\"\n                                                      )","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.398918Z","iopub.execute_input":"2021-08-04T12:56:06.399261Z","iopub.status.idle":"2021-08-04T12:56:06.408180Z","shell.execute_reply.started":"2021-08-04T12:56:06.399227Z","shell.execute_reply":"2021-08-04T12:56:06.407413Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import math\n\n# # from documentation: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n#         scheduler.step(loss)\n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")\n\n\ndef test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    test_loss, correct = 0, 0\n    \n    model.eval()\n    \n    predictions = []\n    targets = []\n    with torch.no_grad():\n        for X, y in dataloader:\n            \n            X = X.to(device=device)\n            y = y.to(device=device)\n            \n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            \n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel() #test_df[\"target\"].values\n    auc = sklearn.metrics.roc_auc_score(targets, predictions)\n\n    test_loss /= size\n#     auc /= size\n    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n    print(f\"Avg loss: {test_loss}, AUC = {auc} \\n\")\n    \n    return test_loss, auc","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.410369Z","iopub.execute_input":"2021-08-04T12:56:06.410605Z","iopub.status.idle":"2021-08-04T12:56:06.422519Z","shell.execute_reply.started":"2021-08-04T12:56:06.410580Z","shell.execute_reply":"2021-08-04T12:56:06.421504Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Training Loop with AMP(automatic mixed precision)\n# supposed to speed up training with GPU but didn't seem to work all that well\n\n# mixed precision scaler\nscaler = torch.cuda.amp.GradScaler()\n\ndef train_loop_amp(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        \n        # forward\n        with torch.cuda.amp.autocast():\n            pred = model(X)\n            loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.423735Z","iopub.execute_input":"2021-08-04T12:56:06.424076Z","iopub.status.idle":"2021-08-04T12:56:06.436559Z","shell.execute_reply.started":"2021-08-04T12:56:06.424043Z","shell.execute_reply":"2021-08-04T12:56:06.435726Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.438003Z","iopub.execute_input":"2021-08-04T12:56:06.438390Z","iopub.status.idle":"2021-08-04T12:56:06.450432Z","shell.execute_reply.started":"2021-08-04T12:56:06.438354Z","shell.execute_reply":"2021-08-04T12:56:06.449393Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# def train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5):\n#     # lowest_loss = np.inf #float(\"inf\")\n#     top_3_models = []\n#     for t in range(epochs):\n#         print(f\"Epoch {t+1}\\n-------------------------------\")\n# #         if device == \"cuda\":\n# #             train_loop_amp(train_loader, model, loss_function, optimizer)\n# #         else:\n# #             train_loop(train_loader, model, loss_function, optimizer)\n\n\n#         train_loop(train_loader, model, loss_function, optimizer)\n#         test_loss = test_loop(test_loader, model, loss_function)\n        \n#         # saving model checkpoint\n#         checkpoint = {\"epoch\": t+1, \n#                       \"model_state\": model.state_dict(), \n#                       \"optimizer_state\": optimizer.state_dict(),\n#                       \"scheduler_state\": scheduler.state_dict(), \n#                       \"loss\": test_loss}\n        \n#         if len(top_3_models) == 0:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n        \n#         if test_loss < top_3_models[0][\"loss\"]:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n\n#         if len(top_3_models) > 3:\n#             file_to_remove = top_3_models[0][\"filename\"]\n#             os.remove(file_to_remove)\n#             top_3_models.pop(0)\n\n#         # sort in descending order by loss \n#         top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n#         # print(f\"top_3_models length: {len(top_3_models)}\")\n            \n#     print(\"Done!\")\n    \n#     return model\n\n\ndef train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5, epochs_pretrained=0):\n    # lowest_loss = np.inf #float(\"inf\")\n    top_3_models = []\n    for t in range(epochs):\n        print(f\"Epoch {t+1}[{epochs_pretrained+t+1} in total]\\n-------------------------------\")\n#         if device == \"cuda\":\n#             train_loop_amp(train_loader, model, loss_function, optimizer)\n#         else:\n#             train_loop(train_loader, model, loss_function, optimizer)\n\n\n        train_loop(train_loader, model, loss_function, optimizer)\n        test_loss, test_auc = test_loop(test_loader, model, loss_function)\n        \n        scheduler.step(test_auc)\n        # saving model checkpoint\n        checkpoint = {\"epoch\": epochs_pretrained+t+1, \n                      \"model_state\": model.state_dict(), \n                      \"optimizer_state\": optimizer.state_dict(),\n                      \"scheduler_state\": scheduler.state_dict(), \n                      \"loss\": test_loss, \n                      \"auc\": test_auc}\n        \n        save_location = f\"./VGG16_bn_model_checkpoint_epoch_{epochs_pretrained+t+1}.pt\"\n        \n        # always save on first epoch\n        if len(top_3_models) == 0:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # save if loss is lower than highest/worst loss of saved models\n        if test_loss < top_3_models[0][\"loss\"]:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # removes worst performing model, but only if there are 3 or more models already saved\n        # keeps the 3 best models(measured by loss on validation set)\n        if len(top_3_models) > 3:\n            file_to_remove = top_3_models[0][\"filename\"]\n            os.remove(file_to_remove)\n            top_3_models.pop(0)\n\n        # sort in descending order by loss \n        top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n        # print(f\"top_3_models length: {len(top_3_models)}\")\n        \n        # always save last epoch\n        if t == epochs-1:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n            \n    print(\"Done!\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.451765Z","iopub.execute_input":"2021-08-04T12:56:06.452329Z","iopub.status.idle":"2021-08-04T12:56:06.464847Z","shell.execute_reply.started":"2021-08-04T12:56:06.452287Z","shell.execute_reply":"2021-08-04T12:56:06.464028Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, train_loader, test_loader, loss_function, optimizer, \n                    epochs=10, epochs_pretrained=0) #model_checkpoint[\"epoch\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:56:06.465889Z","iopub.execute_input":"2021-08-04T12:56:06.467101Z","iopub.status.idle":"2021-08-04T14:19:49.850016Z","shell.execute_reply.started":"2021-08-04T12:56:06.467064Z","shell.execute_reply":"2021-08-04T14:19:49.848896Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1[1 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0003054776079131871, AUC = 0.8695693627840458 \n\nEpoch 2[2 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00022449611536899867, AUC = 0.8643678160919541 \n\nEpoch 3[3 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00017891850332604986, AUC = 0.8587372212511255 \n\nEpoch 4[4 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0001779834152270449, AUC = 0.8725144340272261 \n\nEpoch 5[5 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00022927935058383145, AUC = 0.8798082525557498 \n\nEpoch 6[6 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00018694231085931287, AUC = 0.8785952645796917 \n\nEpoch 7[7 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00014785740832980063, AUC = 0.8874834472164839 \n\nEpoch 8[8 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00016247112187451506, AUC = 0.8738174691456115 \n\nEpoch 9[9 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00015219141498453738, AUC = 0.888293871497431 \n\nEpoch 10[10 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0001657907614906659, AUC = 0.883012871444462 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"# def get_predictions(dataloader, model):\n#     predictions = []\n#     model.eval()\n\n#     with torch.no_grad():\n#         for X, y in dataloader:\n#             X = X.to(device=device)\n#             pred = model(X)\n#             for value in pred:\n#                 predictions.append(value.cpu().numpy()[0])\n            \n#     return predictions\n\n# def predict_multiple_epochs(dataloader, model, epochs=1):\n#     # Note: must use dataloader with batch_size=1\n#     predictions = np.zeros(len(dataloader.dataset))\n#     model.eval()\n    \n#     for i in range(epochs):\n#         print(f\"Epoch: {i+1}\")\n#         j = 0\n#         with torch.no_grad():\n#             for X, y in dataloader:\n#                 X = X.to(device=device)\n#                 pred = model(X)\n#                 predictions[j] += pred[0][0].cpu().numpy()\n#                 j += 1\n\n#     predictions = predictions * (1.0/epochs)\n            \n#     return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:19:49.851571Z","iopub.execute_input":"2021-08-04T14:19:49.851940Z","iopub.status.idle":"2021-08-04T14:19:49.857194Z","shell.execute_reply.started":"2021-08-04T14:19:49.851897Z","shell.execute_reply":"2021-08-04T14:19:49.856010Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    predictions = []\n    targets = []\n    model.eval()\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X = X.to(device=device)\n            pred = model(X)\n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel()\n            \n    return predictions, targets\n\n\ndef predict_multiple_epochs(dataloader, model, epochs=1):\n    # Note: must use dataloader with batch_size=1\n    predictions = []\n    targets = []\n    model.eval()\n    \n    for i in range(epochs):\n        print(f\"Epoch: {i+1}\")\n        pred, targ = get_predictions(dataloader, model)\n        predictions.append(pred)\n        if i == 0:\n            targets.append(targ)\n            \n    targets = np.array(targets).ravel()\n    predictions = np.mean(predictions, axis=0)\n\n    return predictions, targets","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:19:49.858918Z","iopub.execute_input":"2021-08-04T14:19:49.859490Z","iopub.status.idle":"2021-08-04T14:19:49.872498Z","shell.execute_reply.started":"2021-08-04T14:19:49.859448Z","shell.execute_reply":"2021-08-04T14:19:49.871363Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Reset test loader with batch_size=1\n# so that we can use our predict_multiple_epochs function\n# to perform test-time augmentation\ntest_loader_new = DataLoader(dataset=test_ds, batch_size=1, \n                             num_workers=1, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:19:49.874349Z","iopub.execute_input":"2021-08-04T14:19:49.874820Z","iopub.status.idle":"2021-08-04T14:19:49.881889Z","shell.execute_reply.started":"2021-08-04T14:19:49.874780Z","shell.execute_reply":"2021-08-04T14:19:49.880936Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"predictions, targets = predict_multiple_epochs(test_loader_new, model, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:20:58.299666Z","iopub.execute_input":"2021-08-04T14:20:58.300073Z","iopub.status.idle":"2021-08-04T14:23:39.915750Z","shell.execute_reply.started":"2021-08-04T14:20:58.300038Z","shell.execute_reply":"2021-08-04T14:23:39.914559Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch: 1\nEpoch: 2\nEpoch: 3\nEpoch: 4\nEpoch: 5\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"AUC: {sklearn.metrics.roc_auc_score(targets, predictions)}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:23:39.917519Z","iopub.execute_input":"2021-08-04T14:23:39.917934Z","iopub.status.idle":"2021-08-04T14:23:39.928484Z","shell.execute_reply.started":"2021-08-04T14:23:39.917887Z","shell.execute_reply":"2021-08-04T14:23:39.927381Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"AUC: 0.8947031092748556\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.hist(predictions, bins=20)#, range=(0,1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:23:39.931099Z","iopub.execute_input":"2021-08-04T14:23:39.931516Z","iopub.status.idle":"2021-08-04T14:23:40.107647Z","shell.execute_reply.started":"2021-08-04T14:23:39.931479Z","shell.execute_reply":"2021-08-04T14:23:40.106548Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"filtered_predictions = []\nfor pred in predictions:\n    if pred < 0.05:\n        filtered_predictions.append(0)\n    else:\n        filtered_predictions.append(1)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:23:40.109430Z","iopub.execute_input":"2021-08-04T14:23:40.109853Z","iopub.status.idle":"2021-08-04T14:23:40.127042Z","shell.execute_reply.started":"2021-08-04T14:23:40.109787Z","shell.execute_reply":"2021-08-04T14:23:40.126199Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"test_labels = test_df[\"target\"].values","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:23:40.128348Z","iopub.execute_input":"2021-08-04T14:23:40.128740Z","iopub.status.idle":"2021-08-04T14:23:40.134462Z","shell.execute_reply.started":"2021-08-04T14:23:40.128700Z","shell.execute_reply":"2021-08-04T14:23:40.133582Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_labels, filtered_predictions))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:23:40.135941Z","iopub.execute_input":"2021-08-04T14:23:40.136393Z","iopub.status.idle":"2021-08-04T14:23:40.161340Z","shell.execute_reply.started":"2021-08-04T14:23:40.136328Z","shell.execute_reply":"2021-08-04T14:23:40.159028Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98      3255\n           1       0.22      0.40      0.28        58\n\n    accuracy                           0.96      3313\n   macro avg       0.60      0.69      0.63      3313\nweighted avg       0.98      0.96      0.97      3313\n\n","output_type":"stream"}]},{"cell_type":"code","source":"conf_matrix = confusion_matrix(test_labels, filtered_predictions)\n\nplt.figure(figsize=(14,7))\nsns.heatmap(conf_matrix, annot=True, cbar=True, cmap='Blues', fmt='g')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:23:40.162644Z","iopub.execute_input":"2021-08-04T14:23:40.163139Z","iopub.status.idle":"2021-08-04T14:23:40.584468Z","shell.execute_reply.started":"2021-08-04T14:23:40.163104Z","shell.execute_reply":"2021-08-04T14:23:40.583499Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Confusion Matrix')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x504 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}