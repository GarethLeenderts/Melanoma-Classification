{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T15:59:18.245145Z","iopub.execute_input":"2021-08-03T15:59:18.245525Z","iopub.status.idle":"2021-08-03T15:59:18.256019Z","shell.execute_reply.started":"2021-08-03T15:59:18.245446Z","shell.execute_reply":"2021-08-03T15:59:18.254827Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Process\n\n* Set imports\n* Define model architecture\n* set device(GPU or CPU)\n* Define hyperparameters\n* Create your(custom) Dataset(inherits from the Dataset class)\n    * Define DataSets\n    * Define DataLoaders\n* initialize/instantiate network\n* Compile model\n    * Define loss\n    * Define optimizer\n* Train the network (create training for loop)\n    set model to training mode? model.train()?\n    * for epochs\n        * for batch, features, labels in DataLoader\n            * set data to the device(import for cuda, ie. gpu enabled)\n            * Forward pass: predictions and loss\n            * Backward pass: optimizer.zero_grad() & loss.backward()\n            * Gradient descent: optimizer.step()\n* Define testing/validation loop\n    * remember: set model to evaluation mode(with torch.zero_grad??? or model.eval()???)\n    \n\n* Data Augmentation (extra step for image data)\n    * Done with PyTorch Transforms\n    * `import torchvision.transforms as transforms`\n    * `my_transforms = transforms.Compose([your list of transformations go here])`\n    * tranforms get implemented in datasets when you include them in the `transforms` argument of the dataset","metadata":{}},{"cell_type":"code","source":"# imports\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom tqdm import tqdm  \nimport torchvision.transforms as transforms\n\nimport matplotlib.image as img\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:18.260771Z","iopub.execute_input":"2021-08-03T15:59:18.261055Z","iopub.status.idle":"2021-08-03T15:59:20.449842Z","shell.execute_reply.started":"2021-08-03T15:59:18.261022Z","shell.execute_reply":"2021-08-03T15:59:20.449017Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nlearning_rate = 0.001 #0.0003 #0.001\nbatch_size = 80 #80 #16 #32 #64","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:20.451277Z","iopub.execute_input":"2021-08-03T15:59:20.451616Z","iopub.status.idle":"2021-08-03T15:59:20.455887Z","shell.execute_reply.started":"2021-08-03T15:59:20.451578Z","shell.execute_reply":"2021-08-03T15:59:20.454957Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:20.457833Z","iopub.execute_input":"2021-08-03T15:59:20.458323Z","iopub.status.idle":"2021-08-03T15:59:20.552724Z","shell.execute_reply.started":"2021-08-03T15:59:20.458288Z","shell.execute_reply":"2021-08-03T15:59:20.551958Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:20.554268Z","iopub.execute_input":"2021-08-03T15:59:20.554583Z","iopub.status.idle":"2021-08-03T15:59:20.581788Z","shell.execute_reply.started":"2021-08-03T15:59:20.554550Z","shell.execute_reply":"2021-08-03T15:59:20.580852Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df = df[[\"image_name\",\"target\"]].sample(3000, random_state=125)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:20.583116Z","iopub.execute_input":"2021-08-03T15:59:20.583467Z","iopub.status.idle":"2021-08-03T15:59:20.589535Z","shell.execute_reply.started":"2021-08-03T15:59:20.583432Z","shell.execute_reply":"2021-08-03T15:59:20.588507Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# df[[\"image_name\",\"target\"]][df[\"target\"] == 1].info()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:20.591058Z","iopub.execute_input":"2021-08-03T15:59:20.591469Z","iopub.status.idle":"2021-08-03T15:59:20.596679Z","shell.execute_reply.started":"2021-08-03T15:59:20.591436Z","shell.execute_reply":"2021-08-03T15:59:20.595396Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Dataset\nclass Melanoma_Dataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.annotations = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        length = self.annotations.shape[0]\n        return length\n    \n    def __getitem__(self, idx):\n        image_name = self.annotations[\"image_name\"].iloc[idx]\n        target = self.annotations[\"target\"].iloc[idx]\n        image_path = self.root_dir + \"/\" + image_name + \".jpg\"\n        image = img.imread(image_path)\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        \n        target = torch.tensor([target], dtype=torch.float32)\n            \n        return image, target","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:20.598510Z","iopub.execute_input":"2021-08-03T15:59:20.599033Z","iopub.status.idle":"2021-08-03T15:59:20.607905Z","shell.execute_reply.started":"2021-08-03T15:59:20.598992Z","shell.execute_reply":"2021-08-03T15:59:20.606912Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#VGG16 model\n\nbase_model = torchvision.models.resnet152(pretrained=True)\ntorch.save(base_model, \"./resnet152.pt\") # saves to \"output\"\n\n# base_model = torch.load(\"../input/siimmelanomatrainedmodels/resnet152.pt\")\n\n# print(base_model)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:20.611512Z","iopub.execute_input":"2021-08-03T15:59:20.611921Z","iopub.status.idle":"2021-08-03T15:59:45.625660Z","shell.execute_reply.started":"2021-08-03T15:59:20.611884Z","shell.execute_reply":"2021-08-03T15:59:45.624819Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/230M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63a71d416b684990bc38aa4c17a5442c"}},"metadata":{}}]},{"cell_type":"code","source":"# print(base_model)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.627598Z","iopub.execute_input":"2021-08-03T15:59:45.627965Z","iopub.status.idle":"2021-08-03T15:59:45.632112Z","shell.execute_reply.started":"2021-08-03T15:59:45.627914Z","shell.execute_reply":"2021-08-03T15:59:45.631152Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# print(base_model)\n\nclass ResNet152_base(nn.Module):\n    def __init__(self, base_trainable=False):\n        super(ResNet152_base, self).__init__()\n        \n        self.resnet152_base = base_model\n        \n        for param in self.resnet152_base.parameters():\n            param.requires_grad = base_trainable\n        \n        self.fc1 = nn.Linear(1000, 1000)\n        self.fc2 = nn.Linear(1000, 500)\n        self.fc3 = nn.Linear(500, 100)\n        self.fc4 = nn.Linear(100, 1)\n        \n    def forward(self, x):\n        x = self.resnet152_base(x)\n        x = torch.nn.functional.relu(self.fc1(x))\n        x = torch.nn.functional.relu(self.fc2(x))\n        x = torch.nn.functional.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.633584Z","iopub.execute_input":"2021-08-03T15:59:45.634240Z","iopub.status.idle":"2021-08-03T15:59:45.646631Z","shell.execute_reply.started":"2021-08-03T15:59:45.634199Z","shell.execute_reply":"2021-08-03T15:59:45.645727Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.647872Z","iopub.execute_input":"2021-08-03T15:59:45.648213Z","iopub.status.idle":"2021-08-03T15:59:45.701242Z","shell.execute_reply.started":"2021-08-03T15:59:45.648179Z","shell.execute_reply":"2021-08-03T15:59:45.700222Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# augmentations/transforms\nimages_mean = (0.8060590931711208, 0.620982283291032, 0.5915027590675953)\nimages_std = (0.08131081913267031, 0.09455098010432171, 0.10589780296354254)\nimage_transforms = transforms.Compose(\n    [  # Compose makes it possible to have many transforms\n        transforms.ToPILImage(),\n        transforms.RandomRotation(degrees=90),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=images_mean, std=images_std),\n    ]\n)\n\n\ntest_transforms = transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=images_mean, std=images_std),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.702873Z","iopub.execute_input":"2021-08-03T15:59:45.703265Z","iopub.status.idle":"2021-08-03T15:59:45.713767Z","shell.execute_reply.started":"2021-08-03T15:59:45.703224Z","shell.execute_reply":"2021-08-03T15:59:45.712668Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.1)#, random_state=125)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.715497Z","iopub.execute_input":"2021-08-03T15:59:45.715992Z","iopub.status.idle":"2021-08-03T15:59:45.732947Z","shell.execute_reply.started":"2021-08-03T15:59:45.715931Z","shell.execute_reply":"2021-08-03T15:59:45.732097Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"total_samples = len(train_df[\"target\"])\nclass_1_count = sum(train_df[\"target\"]) + 0.0001 #in case class_1_count is zero\nclass_0_count = total_samples - class_1_count\nclass_weights = [total_samples/class_0_count, total_samples/class_1_count]\n\nlist_of_weights = [class_weights[i] for i in train_df[\"target\"]]\nweighted_sampler = WeightedRandomSampler(list_of_weights, num_samples = len(list_of_weights), replacement=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.734346Z","iopub.execute_input":"2021-08-03T15:59:45.734690Z","iopub.status.idle":"2021-08-03T15:59:45.753207Z","shell.execute_reply.started":"2021-08-03T15:59:45.734654Z","shell.execute_reply":"2021-08-03T15:59:45.752320Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # Instantiate Datasets and DataLoaders\n# # root_directory = \"../input/siim-isic-melanoma-classification/jpeg/train\"\nroot_directory = \"../input/siimisic-resized-224x224-jpeg/output_train/train\"\n\ntrain_ds = Melanoma_Dataset(train_df, root_dir=root_directory, transform=image_transforms)\ntest_ds = Melanoma_Dataset(test_df, root_dir=root_directory, transform=image_transforms)\n\ntrain_loader = DataLoader(dataset=train_ds, batch_size=batch_size, sampler=weighted_sampler,\n                          num_workers=1, pin_memory=True) #, shuffle=False) shuffle synonymous with sampler\ntest_loader = DataLoader(dataset=test_ds, batch_size=batch_size, \n                         num_workers=1, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.755342Z","iopub.execute_input":"2021-08-03T15:59:45.755625Z","iopub.status.idle":"2021-08-03T15:59:45.764748Z","shell.execute_reply.started":"2021-08-03T15:59:45.755588Z","shell.execute_reply":"2021-08-03T15:59:45.763877Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Instantiate network\n\nmodel = ResNet152_base(base_trainable=True).to(device)\n\n# model_checkpoint = torch.load(\"./VGG16_bn_model_checkpoint_epoch_4.pt\", \n#                               map_location=device)\n# model_state_dict = model_checkpoint[\"model_state\"]\n# model.load_state_dict(model_state_dict)\n# model = model.to(device)\n\n\n\n# using a pretrained model state_dict\n# model_state_dict = torch.load(\"path-to-state_dict\", \n#                               map_location=device)\n# model.load_state_dict(model_state_dict)\n# model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:45.766261Z","iopub.execute_input":"2021-08-03T15:59:45.766792Z","iopub.status.idle":"2021-08-03T15:59:50.261224Z","shell.execute_reply.started":"2021-08-03T15:59:45.766700Z","shell.execute_reply":"2021-08-03T15:59:50.260343Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# print(model_checkpoint[\"scheduler_state\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.262540Z","iopub.execute_input":"2021-08-03T15:59:50.262884Z","iopub.status.idle":"2021-08-03T15:59:50.268256Z","shell.execute_reply.started":"2021-08-03T15:59:50.262848Z","shell.execute_reply":"2021-08-03T15:59:50.267537Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Focal Loss Function\n# from this blog post: https://amaarora.github.io/2020/06/29/FocalLoss.html\n\nclass WeightedFocalLoss(nn.Module):\n    \"Non weighted version of Focal Loss\"\n    def __init__(self, alpha=.25, gamma=2):\n        super(WeightedFocalLoss, self).__init__()\n        self.alpha = torch.tensor([alpha, 1-alpha]).to(device)  #.cuda() #remember to define \"device\"\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        targets = targets.type(torch.long)\n        at = self.alpha.gather(0, targets.data.view(-1))\n        pt = torch.exp(-BCE_loss)\n        F_loss = at*(1-pt)**self.gamma * BCE_loss\n        return F_loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.269550Z","iopub.execute_input":"2021-08-03T15:59:50.270124Z","iopub.status.idle":"2021-08-03T15:59:50.282057Z","shell.execute_reply.started":"2021-08-03T15:59:50.270088Z","shell.execute_reply":"2021-08-03T15:59:50.281293Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class RMSLELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self, pred, actual):\n        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.283586Z","iopub.execute_input":"2021-08-03T15:59:50.283975Z","iopub.status.idle":"2021-08-03T15:59:50.292288Z","shell.execute_reply.started":"2021-08-03T15:59:50.283942Z","shell.execute_reply":"2021-08-03T15:59:50.291425Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# # Loss and optimizer\n# # loss_function = nn.BCEWithLogitsLoss()\n# loss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\n# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# # learning rate scheduler\n# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate, \n#                                               max_lr=0.5,step_size_up=5,mode=\"triangular2\")\n\n# loss_function = nn.MSELoss()\n# loss_function = RMSLELoss()\n\nloss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\n\n# from abishek thakur: https://www.kaggle.com/abhishek/melanoma-detection-with-pytorch?scriptVersionId=35193166\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                       patience=3, \n                                                       threshold=0.001, \n                                                       mode=\"min\"\n                                                      )","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.293408Z","iopub.execute_input":"2021-08-03T15:59:50.293753Z","iopub.status.idle":"2021-08-03T15:59:50.307939Z","shell.execute_reply.started":"2021-08-03T15:59:50.293719Z","shell.execute_reply":"2021-08-03T15:59:50.307111Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import math\n\n# # from documentation: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n#         scheduler.step(loss)\n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")\n\n\ndef test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    test_loss, correct = 0, 0\n    \n    model.eval()\n    \n    predictions = []\n    targets = []\n    with torch.no_grad():\n        for X, y in dataloader:\n            \n            X = X.to(device=device)\n            y = y.to(device=device)\n            \n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            \n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel() #test_df[\"target\"].values\n    auc = sklearn.metrics.roc_auc_score(targets, predictions)\n\n    test_loss /= size\n#     auc /= size\n    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n    print(f\"Avg loss: {test_loss}, AUC = {auc} \\n\")\n    \n    return test_loss, auc","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.309079Z","iopub.execute_input":"2021-08-03T15:59:50.309498Z","iopub.status.idle":"2021-08-03T15:59:50.323241Z","shell.execute_reply.started":"2021-08-03T15:59:50.309461Z","shell.execute_reply":"2021-08-03T15:59:50.322228Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Training Loop with AMP(automatic mixed precision)\n# supposed to speed up training with GPU but didn't seem to work all that well\n\n# mixed precision scaler\nscaler = torch.cuda.amp.GradScaler()\n\ndef train_loop_amp(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        \n        # forward\n        with torch.cuda.amp.autocast():\n            pred = model(X)\n            loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.324680Z","iopub.execute_input":"2021-08-03T15:59:50.325121Z","iopub.status.idle":"2021-08-03T15:59:50.335912Z","shell.execute_reply.started":"2021-08-03T15:59:50.325081Z","shell.execute_reply":"2021-08-03T15:59:50.335045Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.340275Z","iopub.execute_input":"2021-08-03T15:59:50.340682Z","iopub.status.idle":"2021-08-03T15:59:50.348868Z","shell.execute_reply.started":"2021-08-03T15:59:50.340646Z","shell.execute_reply":"2021-08-03T15:59:50.347852Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# def train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5):\n#     # lowest_loss = np.inf #float(\"inf\")\n#     top_3_models = []\n#     for t in range(epochs):\n#         print(f\"Epoch {t+1}\\n-------------------------------\")\n# #         if device == \"cuda\":\n# #             train_loop_amp(train_loader, model, loss_function, optimizer)\n# #         else:\n# #             train_loop(train_loader, model, loss_function, optimizer)\n\n\n#         train_loop(train_loader, model, loss_function, optimizer)\n#         test_loss = test_loop(test_loader, model, loss_function)\n        \n#         # saving model checkpoint\n#         checkpoint = {\"epoch\": t+1, \n#                       \"model_state\": model.state_dict(), \n#                       \"optimizer_state\": optimizer.state_dict(),\n#                       \"scheduler_state\": scheduler.state_dict(), \n#                       \"loss\": test_loss}\n        \n#         if len(top_3_models) == 0:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n        \n#         if test_loss < top_3_models[0][\"loss\"]:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n\n#         if len(top_3_models) > 3:\n#             file_to_remove = top_3_models[0][\"filename\"]\n#             os.remove(file_to_remove)\n#             top_3_models.pop(0)\n\n#         # sort in descending order by loss \n#         top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n#         # print(f\"top_3_models length: {len(top_3_models)}\")\n            \n#     print(\"Done!\")\n    \n#     return model\n\n\ndef train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5, epochs_pretrained=0):\n    # lowest_loss = np.inf #float(\"inf\")\n    top_3_models = []\n    for t in range(epochs):\n        print(f\"Epoch {t+1}[{epochs_pretrained+t+1} in total]\\n-------------------------------\")\n#         if device == \"cuda\":\n#             train_loop_amp(train_loader, model, loss_function, optimizer)\n#         else:\n#             train_loop(train_loader, model, loss_function, optimizer)\n\n\n        train_loop(train_loader, model, loss_function, optimizer)\n        test_loss, test_auc = test_loop(test_loader, model, loss_function)\n        \n        scheduler.step(test_loss)\n        # saving model checkpoint\n        checkpoint = {\"epoch\": epochs_pretrained+t+1, \n                      \"model_state\": model.state_dict(), \n                      \"optimizer_state\": optimizer.state_dict(),\n                      \"scheduler_state\": scheduler.state_dict(), \n                      \"loss\": test_loss, \n                      \"auc\": test_auc}\n        \n        save_location = f\"./ResNet152_model_checkpoint_epoch_{epochs_pretrained+t+1}.pt\"\n        \n        # always save on first epoch\n        if len(top_3_models) == 0:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # save if loss is lower than highest/worst loss of saved models\n        if test_loss < top_3_models[0][\"loss\"]:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # removes worst performing model, but only if there are 3 or more models already saved\n        # keeps the 3 best models(measured by loss on validation set)\n        if len(top_3_models) > 3:\n            file_to_remove = top_3_models[0][\"filename\"]\n            os.remove(file_to_remove)\n            top_3_models.pop(0)\n\n        # sort in descending order by loss \n        top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n        # print(f\"top_3_models length: {len(top_3_models)}\")\n        \n        # always save last epoch\n        if t == epochs-1:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n            \n    print(\"Done!\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.351007Z","iopub.execute_input":"2021-08-03T15:59:50.351459Z","iopub.status.idle":"2021-08-03T15:59:50.365289Z","shell.execute_reply.started":"2021-08-03T15:59:50.351419Z","shell.execute_reply":"2021-08-03T15:59:50.364497Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, train_loader, test_loader, loss_function, optimizer, \n                    epochs=10, epochs_pretrained=0) #model_checkpoint[\"epoch\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T15:59:50.366643Z","iopub.execute_input":"2021-08-03T15:59:50.367036Z","iopub.status.idle":"2021-08-03T17:20:43.791668Z","shell.execute_reply.started":"2021-08-03T15:59:50.367000Z","shell.execute_reply":"2021-08-03T17:20:43.790088Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1[1 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0002379139192085269, AUC = 0.8910450466781474 \n\nEpoch 2[2 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00017689297103918718, AUC = 0.8902429076407142 \n\nEpoch 3[3 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0001645778505979997, AUC = 0.8774177467597208 \n\nEpoch 4[4 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00016755586712429436, AUC = 0.8778301459258588 \n\nEpoch 5[5 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0001789448587288543, AUC = 0.8747802048400254 \n\nEpoch 6[6 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00017061602579918316, AUC = 0.8908003262938458 \n\nEpoch 7[7 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00017111801306805366, AUC = 0.8881990392458987 \n\nEpoch 8[8 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00015495433513209485, AUC = 0.8751835402882264 \n\nEpoch 9[9 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00017418200032197099, AUC = 0.8854436689930208 \n\nEpoch 10[10 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00017704158877870116, AUC = 0.8725233390736881 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"# def get_predictions(dataloader, model):\n#     predictions = []\n#     model.eval()\n\n#     with torch.no_grad():\n#         for X, y in dataloader:\n#             X = X.to(device=device)\n#             pred = model(X)\n#             for value in pred:\n#                 predictions.append(value.cpu().numpy()[0])\n            \n#     return predictions\n\n# def predict_multiple_epochs(dataloader, model, epochs=1):\n#     # Note: must use dataloader with batch_size=1\n#     predictions = np.zeros(len(dataloader.dataset))\n#     model.eval()\n    \n#     for i in range(epochs):\n#         print(f\"Epoch: {i+1}\")\n#         j = 0\n#         with torch.no_grad():\n#             for X, y in dataloader:\n#                 X = X.to(device=device)\n#                 pred = model(X)\n#                 predictions[j] += pred[0][0].cpu().numpy()\n#                 j += 1\n\n#     predictions = predictions * (1.0/epochs)\n            \n#     return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:20:43.793318Z","iopub.execute_input":"2021-08-03T17:20:43.793674Z","iopub.status.idle":"2021-08-03T17:20:43.798408Z","shell.execute_reply.started":"2021-08-03T17:20:43.793634Z","shell.execute_reply":"2021-08-03T17:20:43.797392Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    predictions = []\n    targets = []\n    model.eval()\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X = X.to(device=device)\n            pred = model(X)\n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel()\n            \n    return predictions, targets\n\n\ndef predict_multiple_epochs(dataloader, model, epochs=1):\n    # Note: must use dataloader with batch_size=1\n    predictions = []\n    targets = []\n    model.eval()\n    \n    for i in range(epochs):\n        print(f\"Epoch: {i+1}\")\n        pred, targ = get_predictions(dataloader, model)\n        predictions.append(pred)\n        if i == 0:\n            targets.append(targ)\n            \n    targets = np.array(targets).ravel()\n    predictions = np.mean(predictions, axis=0)\n\n    return predictions, targets","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:20:43.800001Z","iopub.execute_input":"2021-08-03T17:20:43.800563Z","iopub.status.idle":"2021-08-03T17:20:43.813874Z","shell.execute_reply.started":"2021-08-03T17:20:43.800523Z","shell.execute_reply":"2021-08-03T17:20:43.812911Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Reset test loader with batch_size=1\n# so that we can use our predict_multiple_epochs function\n# to perform test-time augmentation\ntest_loader_new = DataLoader(dataset=test_ds, batch_size=1, \n                             num_workers=1, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:20:43.815477Z","iopub.execute_input":"2021-08-03T17:20:43.815910Z","iopub.status.idle":"2021-08-03T17:20:43.824403Z","shell.execute_reply.started":"2021-08-03T17:20:43.815869Z","shell.execute_reply":"2021-08-03T17:20:43.823386Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"predictions, targets = predict_multiple_epochs(test_loader_new, model, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:20:43.825833Z","iopub.execute_input":"2021-08-03T17:20:43.826247Z","iopub.status.idle":"2021-08-03T17:35:27.339311Z","shell.execute_reply.started":"2021-08-03T17:20:43.826204Z","shell.execute_reply":"2021-08-03T17:35:27.338306Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch: 1\nEpoch: 2\nEpoch: 3\nEpoch: 4\nEpoch: 5\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"AUC: {sklearn.metrics.roc_auc_score(targets, predictions)}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:35:27.340776Z","iopub.execute_input":"2021-08-03T17:35:27.341126Z","iopub.status.idle":"2021-08-03T17:35:27.351451Z","shell.execute_reply.started":"2021-08-03T17:35:27.341089Z","shell.execute_reply":"2021-08-03T17:35:27.350279Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"AUC: 0.8882488896945527\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.hist(predictions, bins=20)#, range=(0,1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:35:27.353083Z","iopub.execute_input":"2021-08-03T17:35:27.353427Z","iopub.status.idle":"2021-08-03T17:35:27.527679Z","shell.execute_reply.started":"2021-08-03T17:35:27.353392Z","shell.execute_reply":"2021-08-03T17:35:27.526667Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"filtered_predictions = []\nfor pred in predictions:\n    if pred < 0.05:\n        filtered_predictions.append(0)\n    else:\n        filtered_predictions.append(1)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:35:27.529232Z","iopub.execute_input":"2021-08-03T17:35:27.529597Z","iopub.status.idle":"2021-08-03T17:35:27.544042Z","shell.execute_reply.started":"2021-08-03T17:35:27.529561Z","shell.execute_reply":"2021-08-03T17:35:27.543005Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"test_labels = test_df[\"target\"].values","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:35:27.545398Z","iopub.execute_input":"2021-08-03T17:35:27.545809Z","iopub.status.idle":"2021-08-03T17:35:27.552974Z","shell.execute_reply.started":"2021-08-03T17:35:27.545772Z","shell.execute_reply":"2021-08-03T17:35:27.552079Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_labels, filtered_predictions))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:35:27.554124Z","iopub.execute_input":"2021-08-03T17:35:27.554578Z","iopub.status.idle":"2021-08-03T17:35:27.572769Z","shell.execute_reply.started":"2021-08-03T17:35:27.554551Z","shell.execute_reply":"2021-08-03T17:35:27.571701Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99      3245\n           1       0.28      0.13      0.18        68\n\n    accuracy                           0.98      3313\n   macro avg       0.63      0.56      0.58      3313\nweighted avg       0.97      0.98      0.97      3313\n\n","output_type":"stream"}]},{"cell_type":"code","source":"conf_matrix = confusion_matrix(test_labels, filtered_predictions)\n\nplt.figure(figsize=(14,7))\nsns.heatmap(conf_matrix, annot=True, cbar=True, cmap='Blues', fmt='g')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T17:35:27.573904Z","iopub.execute_input":"2021-08-03T17:35:27.574253Z","iopub.status.idle":"2021-08-03T17:35:27.834480Z","shell.execute_reply.started":"2021-08-03T17:35:27.574227Z","shell.execute_reply":"2021-08-03T17:35:27.833674Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Confusion Matrix')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x504 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}