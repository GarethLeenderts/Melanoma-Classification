{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T07:20:33.027616Z","iopub.execute_input":"2021-08-03T07:20:33.028271Z","iopub.status.idle":"2021-08-03T07:20:33.054013Z","shell.execute_reply.started":"2021-08-03T07:20:33.028130Z","shell.execute_reply":"2021-08-03T07:20:33.052621Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Process\n\n* Set imports\n* Define model architecture\n* set device(GPU or CPU)\n* Define hyperparameters\n* Create your(custom) Dataset(inherits from the Dataset class)\n    * Define DataSets\n    * Define DataLoaders\n* initialize/instantiate network\n* Compile model\n    * Define loss\n    * Define optimizer\n* Train the network (create training for loop)\n    set model to training mode? model.train()?\n    * for epochs\n        * for batch, features, labels in DataLoader\n            * set data to the device(import for cuda, ie. gpu enabled)\n            * Forward pass: predictions and loss\n            * Backward pass: optimizer.zero_grad() & loss.backward()\n            * Gradient descent: optimizer.step()\n* Define testing/validation loop\n    * remember: set model to evaluation mode(with torch.zero_grad??? or model.eval()???)\n    \n\n* Data Augmentation (extra step for image data)\n    * Done with PyTorch Transforms\n    * `import torchvision.transforms as transforms`\n    * `my_transforms = transforms.Compose([your list of transformations go here])`\n    * tranforms get implemented in datasets when you include them in the `transforms` argument of the dataset","metadata":{}},{"cell_type":"code","source":"# imports\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom tqdm import tqdm  \nimport torchvision.transforms as transforms\n\nimport matplotlib.image as img\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:33.057391Z","iopub.execute_input":"2021-08-03T07:20:33.059161Z","iopub.status.idle":"2021-08-03T07:20:36.001161Z","shell.execute_reply.started":"2021-08-03T07:20:33.059097Z","shell.execute_reply":"2021-08-03T07:20:35.999976Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nlearning_rate = 0.001 #3e-4 #0.001\nbatch_size = 96 #24 #256 #80 #16 #32 #64","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.003973Z","iopub.execute_input":"2021-08-03T07:20:36.004492Z","iopub.status.idle":"2021-08-03T07:20:36.010344Z","shell.execute_reply.started":"2021-08-03T07:20:36.004430Z","shell.execute_reply":"2021-08-03T07:20:36.008740Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.013076Z","iopub.execute_input":"2021-08-03T07:20:36.013725Z","iopub.status.idle":"2021-08-03T07:20:36.087349Z","shell.execute_reply.started":"2021-08-03T07:20:36.013527Z","shell.execute_reply":"2021-08-03T07:20:36.086169Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.089305Z","iopub.execute_input":"2021-08-03T07:20:36.089915Z","iopub.status.idle":"2021-08-03T07:20:36.184591Z","shell.execute_reply.started":"2021-08-03T07:20:36.089870Z","shell.execute_reply":"2021-08-03T07:20:36.183538Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.187046Z","iopub.execute_input":"2021-08-03T07:20:36.187353Z","iopub.status.idle":"2021-08-03T07:20:36.221744Z","shell.execute_reply.started":"2021-08-03T07:20:36.187323Z","shell.execute_reply":"2021-08-03T07:20:36.220244Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df = df[[\"image_name\",\"target\"]].sample(3000, random_state=125)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.223569Z","iopub.execute_input":"2021-08-03T07:20:36.224070Z","iopub.status.idle":"2021-08-03T07:20:36.228977Z","shell.execute_reply.started":"2021-08-03T07:20:36.224028Z","shell.execute_reply":"2021-08-03T07:20:36.227796Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# df[[\"image_name\",\"target\"]][df[\"target\"] == 1].info()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.233460Z","iopub.execute_input":"2021-08-03T07:20:36.234338Z","iopub.status.idle":"2021-08-03T07:20:36.242242Z","shell.execute_reply.started":"2021-08-03T07:20:36.234292Z","shell.execute_reply":"2021-08-03T07:20:36.241022Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Dataset\nclass Melanoma_Dataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.annotations = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        length = self.annotations.shape[0]\n        return length\n    \n    def __getitem__(self, idx):\n        image_name = self.annotations[\"image_name\"].iloc[idx]\n        target = self.annotations[\"target\"].iloc[idx]\n        image_path = self.root_dir + \"/\" + image_name + \".jpg\"\n        image = img.imread(image_path)\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        \n        target = torch.tensor([target], dtype=torch.float32)\n            \n        return image, target","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.245322Z","iopub.execute_input":"2021-08-03T07:20:36.245970Z","iopub.status.idle":"2021-08-03T07:20:36.256915Z","shell.execute_reply.started":"2021-08-03T07:20:36.245911Z","shell.execute_reply":"2021-08-03T07:20:36.255102Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# # vgg_base_state = torch.load(\"../input/melanoma-prediction-base-model-state-dictionaries/vgg16bn_base_state_dict_new.pt\", map_location=device)\n# # wideresnet_base_state = torch.load(\"../input/melanoma-prediction-base-model-state-dictionaries/wideresnet50_base_state_dict_new.pt\", map_location=device)\n# # resnext_base_state = torch.load(\"../input/melanoma-prediction-base-model-state-dictionaries/resnext50_base_state_dict_new.pt\", map_location=device)\n\n\n# # base_model = torchvision.models.wide_resnet50_2(pretrained=True)\n# # torch.save(base_model, \"./wide_resnet50_2.pt\") # saves to \"output\"\n\n# vgg16_base_model = torch.load(\"../input/siimmelanomatrainedmodels/vgg16_bn.pt\")\n# wideresnet50_base_model = torch.load(\"../input/siimmelanomatrainedmodels/wide_resnet50_2.pt\")\n# resnext50_base_model = torch.load(\"../input/siimmelanomatrainedmodels/resnext50_32x4d.pt\")\n\n# # vgg16_base_model.load_state_dict(vgg_base_state)\n# # wideresnet50_base_model.load_state_dict(wideresnet_base_state)\n# # resnext50_base_model.load_state_dict(resnext_base_state)\n\n\n# class EnsembleModel(nn.Module):\n#     def __init__(self, trainable=[False, False, False, True]):\n#         super(EnsembleModel, self).__init__()\n        \n#         self.wide_resnet50_base = wideresnet50_base_model\n#         self.vgg16_base = vgg16_base_model\n#         self.resnext50_base = resnext50_base_model\n\n#         for param in self.wide_resnet50_base.parameters():\n#             param.requires_grad = trainable[0]\n            \n#         for param in self.vgg16_base.parameters():\n#             param.requires_grad = trainable[1]\n            \n#         for param in self.resnext50_base.parameters():\n#             param.requires_grad = trainable[2]\n        \n#         self.fc1 = nn.Linear(3000, 3000)\n#         self.fc2 = nn.Linear(3000, 1500)\n#         self.fc3 = nn.Linear(1500, 1000)\n#         self.fc4 = nn.Linear(1000, 500)\n#         self.fc5 = nn.Linear(500, 100)\n#         self.fc6 = nn.Linear(100, 1)\n        \n#         end_layers = [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5, self.fc6]\n        \n#         for layer in end_layers:\n#             layer.requires_grad = trainable[3]\n        \n#     def forward(self, x):\n#         x1 = self.wide_resnet50_base(x)\n#         x2 = self.resnext50_base(x)\n#         x3 = self.vgg16_base(x)\n        \n#         x = torch.cat((x1,x2,x3), dim=1)\n        \n#         x = torch.relu(self.fc1(x))\n#         x = torch.relu(self.fc2(x))\n#         x = torch.relu(self.fc3(x))\n#         x = torch.relu(self.fc4(x))\n#         x = torch.relu(self.fc5(x))\n#         x = self.fc6(x)\n# #         x = torch.nn.functional.relu(self.fc1(x))\n# #         x = torch.nn.functional.relu(self.fc2(x))\n# #         x = (x1 + x2 + x3)/3.0\n#         return x","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.259069Z","iopub.execute_input":"2021-08-03T07:20:36.259613Z","iopub.status.idle":"2021-08-03T07:20:36.272754Z","shell.execute_reply.started":"2021-08-03T07:20:36.259567Z","shell.execute_reply":"2021-08-03T07:20:36.271471Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# model = EnsembleModel()\n\n# model.state_dict().keys()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.276425Z","iopub.execute_input":"2021-08-03T07:20:36.276797Z","iopub.status.idle":"2021-08-03T07:20:36.289592Z","shell.execute_reply.started":"2021-08-03T07:20:36.276765Z","shell.execute_reply":"2021-08-03T07:20:36.288393Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# EfficientNet Model built from scratch by Aladdin Persson\n# GitHub code: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/CNN_architectures/pytorch_efficientnet.py\n# YouTube Tutorials:\n## EfficientNet Paper Walkthrough: https://www.youtube.com/watch?v=_OZsGQHB41s\n## EfficientNet from scratch in Pytorch: https://www.youtube.com/watch?v=fR_0o25kigM\n\n\nimport torch\nimport torch.nn as nn\nfrom math import ceil\n\nbase_model = [\n    # expand_ratio, channels, repeats, stride, kernel_size\n    [1, 16, 1, 1, 3],\n    [6, 24, 2, 2, 3],\n    [6, 40, 2, 2, 5],\n    [6, 80, 3, 2, 3],\n    [6, 112, 3, 1, 5],\n    [6, 192, 4, 2, 5],\n    [6, 320, 1, 1, 3],\n]\n\n# phi_values = {\n#     # tuple of: (phi_value, resolution, drop_rate)\n#     \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\n#     \"b1\": (0.5, 240, 0.2),\n#     \"b2\": (1, 260, 0.3),\n#     \"b3\": (2, 300, 0.3),\n#     \"b4\": (3, 380, 0.4),\n#     \"b5\": (4, 456, 0.4),\n#     \"b6\": (5, 528, 0.5),\n#     \"b7\": (6, 600, 0.5),\n# }\n\nphi_values = {\n    # tuple of: (phi_value, resolution, drop_rate)\n    \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\n    \"b1\": (0.5, 224, 0.2),\n    \"b2\": (1, 224, 0.3),\n    \"b3\": (2, 224, 0.3),\n    \"b4\": (3, 224, 0.4),\n    \"b5\": (4, 224, 0.4),\n    \"b6\": (5, 224, 0.5),\n    \"b7\": (6, 224, 0.5),\n}\n\nclass CNNBlock(nn.Module):\n    def __init__(\n            self, in_channels, out_channels, kernel_size, stride, padding, groups=1\n    ):\n        super(CNNBlock, self).__init__()\n        self.cnn = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            groups=groups,\n            bias=False,\n        )\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.silu = nn.SiLU() # SiLU <-> Swish\n\n    def forward(self, x):\n        return self.silu(self.bn(self.cnn(x)))\n\nclass SqueezeExcitation(nn.Module):\n    def __init__(self, in_channels, reduced_dim):\n        super(SqueezeExcitation, self).__init__()\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1), # C x H x W -> C x 1 x 1\n            nn.Conv2d(in_channels, reduced_dim, 1),\n            nn.SiLU(),\n            nn.Conv2d(reduced_dim, in_channels, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        return x * self.se(x)\n\nclass InvertedResidualBlock(nn.Module):\n    def __init__(\n            self,\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride,\n            padding,\n            expand_ratio,\n            reduction=4, # squeeze excitation\n            survival_prob=0.8, # for stochastic depth\n    ):\n        super(InvertedResidualBlock, self).__init__()\n        self.survival_prob = 0.8\n        self.use_residual = in_channels == out_channels and stride == 1\n        hidden_dim = in_channels * expand_ratio\n        self.expand = in_channels != hidden_dim\n        reduced_dim = int(in_channels / reduction)\n\n        if self.expand:\n            self.expand_conv = CNNBlock(\n                in_channels, hidden_dim, kernel_size=3, stride=1, padding=1,\n            )\n\n        self.conv = nn.Sequential(\n            CNNBlock(\n                hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim,\n            ),\n            SqueezeExcitation(hidden_dim, reduced_dim),\n            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n\n    def stochastic_depth(self, x):\n        if not self.training:\n            return x\n\n        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n        return torch.div(x, self.survival_prob) * binary_tensor\n\n    def forward(self, inputs):\n        x = self.expand_conv(inputs) if self.expand else inputs\n\n        if self.use_residual:\n            return self.stochastic_depth(self.conv(x)) + inputs\n        else:\n            return self.conv(x)\n\n\nclass EfficientNet(nn.Module):\n    def __init__(self, version, num_classes):\n        super(EfficientNet, self).__init__()\n        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n        last_channels = ceil(1280 * width_factor)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.features = self.create_features(width_factor, depth_factor, last_channels)\n        self.classifier = nn.Sequential(\n            nn.Dropout(dropout_rate),\n            nn.Linear(last_channels, num_classes),\n        )\n\n    def calculate_factors(self, version, alpha=1.2, beta=1.1):\n        phi, res, drop_rate = phi_values[version]\n        depth_factor = alpha ** phi\n        width_factor = beta ** phi\n        return width_factor, depth_factor, drop_rate\n\n    def create_features(self, width_factor, depth_factor, last_channels):\n        channels = int(32 * width_factor)\n        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]\n        in_channels = channels\n\n        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n            out_channels = 4*ceil(int(channels*width_factor) / 4)\n            layers_repeats = ceil(repeats * depth_factor)\n\n            for layer in range(layers_repeats):\n                features.append(\n                    InvertedResidualBlock(\n                        in_channels,\n                        out_channels,\n                        expand_ratio=expand_ratio,\n                        stride = stride if layer == 0 else 1,\n                        kernel_size=kernel_size,\n                        padding=kernel_size//2, # if k=1:pad=0, k=3:pad=1, k=5:pad=2\n                    )\n                )\n                in_channels = out_channels\n\n        features.append(\n            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)\n        )\n\n        return nn.Sequential(*features)\n\n    def forward(self, x):\n        x = self.pool(self.features(x))\n        return self.classifier(x.view(x.shape[0], -1))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.291680Z","iopub.execute_input":"2021-08-03T07:20:36.292222Z","iopub.status.idle":"2021-08-03T07:20:36.326782Z","shell.execute_reply.started":"2021-08-03T07:20:36.292147Z","shell.execute_reply":"2021-08-03T07:20:36.325543Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# state_dict = torch.load(\"../input/siimmelanomatrainedmodels/EfficientNet_b4_checkpoint_epoch_17.pt\", map_location=device)\n# state_dict = torch.load(\"../input/siimmelanomatrainedmodels/EfficientNet_b7_checkpoint_epoch_13.pt\", map_location=\"cpu\")\n# model_state = state_dict[\"model_state\"]\n\n# optimizer_state = state_dict[\"optimizer_state\"]\n# scheduler_state = state_dict[\"scheduler_state\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.328355Z","iopub.execute_input":"2021-08-03T07:20:36.329300Z","iopub.status.idle":"2021-08-03T07:20:36.343769Z","shell.execute_reply.started":"2021-08-03T07:20:36.329252Z","shell.execute_reply":"2021-08-03T07:20:36.342581Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# print(state_dict[\"loss\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.345447Z","iopub.execute_input":"2021-08-03T07:20:36.346230Z","iopub.status.idle":"2021-08-03T07:20:36.360024Z","shell.execute_reply.started":"2021-08-03T07:20:36.345899Z","shell.execute_reply":"2021-08-03T07:20:36.358786Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# print(state_dict[\"loss\"])\n# print(state_dict[\"auc\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.361692Z","iopub.execute_input":"2021-08-03T07:20:36.362535Z","iopub.status.idle":"2021-08-03T07:20:36.371655Z","shell.execute_reply.started":"2021-08-03T07:20:36.362461Z","shell.execute_reply":"2021-08-03T07:20:36.370550Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# version = \"b0\"\n# phi, res, drop_rate = phi_values[version]\n\nmodel = EfficientNet(version=\"b0\", num_classes=1).to(device)\n# model.load_state_dict(model_state)\n\n# model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:36.372863Z","iopub.execute_input":"2021-08-03T07:20:36.373253Z","iopub.status.idle":"2021-08-03T07:20:41.958341Z","shell.execute_reply.started":"2021-08-03T07:20:36.373223Z","shell.execute_reply":"2021-08-03T07:20:41.957020Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# augmentations/transforms\nimages_mean = (0.8060590931711208, 0.620982283291032, 0.5915027590675953)\nimages_std = (0.08131081913267031, 0.09455098010432171, 0.10589780296354254)\nimage_transforms = transforms.Compose(\n    [  # Compose makes it possible to have many transforms\n        transforms.ToPILImage(),\n        transforms.RandomRotation(degrees=90),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=images_mean, std=images_std),\n        #transforms.Grayscale(num_output_channels=3),\n    ]\n)\n\n\ntest_transforms = transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=images_mean, std=images_std),\n        #transforms.Grayscale(num_output_channels=3),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:41.961276Z","iopub.execute_input":"2021-08-03T07:20:41.961583Z","iopub.status.idle":"2021-08-03T07:20:41.972793Z","shell.execute_reply.started":"2021-08-03T07:20:41.961554Z","shell.execute_reply":"2021-08-03T07:20:41.970876Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.1, random_state=167)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:41.974975Z","iopub.execute_input":"2021-08-03T07:20:41.976127Z","iopub.status.idle":"2021-08-03T07:20:42.003646Z","shell.execute_reply.started":"2021-08-03T07:20:41.975946Z","shell.execute_reply":"2021-08-03T07:20:42.002185Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"total_samples = len(train_df[\"target\"])\nclass_1_count = sum(train_df[\"target\"]) + 0.0001 #in case class_1_count is zero\nclass_0_count = total_samples - class_1_count\nclass_weights = [total_samples/class_0_count, total_samples/class_1_count]\n\nlist_of_weights = [class_weights[i] for i in train_df[\"target\"]]\nweighted_sampler = WeightedRandomSampler(list_of_weights, num_samples = len(list_of_weights), replacement=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.006270Z","iopub.execute_input":"2021-08-03T07:20:42.006788Z","iopub.status.idle":"2021-08-03T07:20:42.026783Z","shell.execute_reply.started":"2021-08-03T07:20:42.006747Z","shell.execute_reply":"2021-08-03T07:20:42.025518Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# # Instantiate Datasets and DataLoaders\n# # root_directory = \"../input/siim-isic-melanoma-classification/jpeg/train\"\nroot_directory = \"../input/siimisic-resized-224x224-jpeg/output_train/train\"\n\ntrain_ds = Melanoma_Dataset(train_df, root_dir=root_directory, transform=image_transforms)\ntest_ds = Melanoma_Dataset(test_df, root_dir=root_directory, transform=image_transforms)\n\ntrain_loader = DataLoader(dataset=train_ds, batch_size=batch_size, sampler=weighted_sampler,\n                          num_workers=1, pin_memory=True, shuffle=False)\ntest_loader = DataLoader(dataset=test_ds, batch_size=batch_size, \n                         num_workers=1, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.028572Z","iopub.execute_input":"2021-08-03T07:20:42.029029Z","iopub.status.idle":"2021-08-03T07:20:42.040122Z","shell.execute_reply.started":"2021-08-03T07:20:42.028984Z","shell.execute_reply":"2021-08-03T07:20:42.038701Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Focal Loss Function\n# from this blog post: https://amaarora.github.io/2020/06/29/FocalLoss.html\n\nclass WeightedFocalLoss(nn.Module):\n    \"Non weighted version of Focal Loss\"\n    def __init__(self, alpha=.25, gamma=2):\n        super(WeightedFocalLoss, self).__init__()\n        self.alpha = torch.tensor([alpha, 1-alpha]).to(device)  #.cuda() #remember to define \"device\"\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        targets = targets.type(torch.long)\n        at = self.alpha.gather(0, targets.data.view(-1))\n        pt = torch.exp(-BCE_loss)\n        F_loss = at*(1-pt)**self.gamma * BCE_loss\n        return F_loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.043033Z","iopub.execute_input":"2021-08-03T07:20:42.044192Z","iopub.status.idle":"2021-08-03T07:20:42.055247Z","shell.execute_reply.started":"2021-08-03T07:20:42.044097Z","shell.execute_reply":"2021-08-03T07:20:42.054187Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# # Loss and optimizer\n# # loss_function = nn.BCEWithLogitsLoss() \n# loss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\n# optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n# # learning rate scheduler\n# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate, \n#                                               max_lr=0.1,step_size_up=5,mode=\"triangular2\")\n\n\n# loss_function = loss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\nloss_function = loss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\n\n\n# from abishek thakur: https://www.kaggle.com/abhishek/melanoma-detection-with-pytorch?scriptVersionId=35193166\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n#                                                        patience=3, \n#                                                        threshold=0.001, \n#                                                        mode=\"max\"\n#                                                       )\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                       patience=3, \n                                                       threshold=0.001, \n                                                       mode=\"min\"\n                                                      )","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.057889Z","iopub.execute_input":"2021-08-03T07:20:42.058400Z","iopub.status.idle":"2021-08-03T07:20:42.073722Z","shell.execute_reply.started":"2021-08-03T07:20:42.058346Z","shell.execute_reply":"2021-08-03T07:20:42.072323Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# optimizer.load_state_dict(optimizer_state)\n# scheduler.load_state_dict(scheduler_state)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.079612Z","iopub.execute_input":"2021-08-03T07:20:42.080141Z","iopub.status.idle":"2021-08-03T07:20:42.089568Z","shell.execute_reply.started":"2021-08-03T07:20:42.080096Z","shell.execute_reply":"2021-08-03T07:20:42.088288Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import math\n\n# # from documentation: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n#         scheduler.step(loss)\n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")\n\n\ndef test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    test_loss, correct = 0, 0\n    \n    model.eval()\n    \n    predictions = []\n    targets = []\n    with torch.no_grad():\n        for X, y in dataloader:\n            \n            X = X.to(device=device)\n            y = y.to(device=device)\n            \n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            \n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel() #test_df[\"target\"].values\n    auc = sklearn.metrics.roc_auc_score(targets, predictions)\n\n    test_loss /= size\n#     auc /= size\n    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n    print(f\"Avg loss: {test_loss}, AUC = {auc} \\n\")\n    \n    return test_loss, auc","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.091789Z","iopub.execute_input":"2021-08-03T07:20:42.092366Z","iopub.status.idle":"2021-08-03T07:20:42.107026Z","shell.execute_reply.started":"2021-08-03T07:20:42.092322Z","shell.execute_reply":"2021-08-03T07:20:42.105557Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Training Loop with AMP(automatic mixed precision)\n\n# mixed precision scaler\nscaler = torch.cuda.amp.GradScaler()\n\ndef train_loop_amp(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        \n        # forward\n        with torch.cuda.amp.autocast():\n            pred = model(X)\n            loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.108891Z","iopub.execute_input":"2021-08-03T07:20:42.109589Z","iopub.status.idle":"2021-08-03T07:20:42.123948Z","shell.execute_reply.started":"2021-08-03T07:20:42.109535Z","shell.execute_reply":"2021-08-03T07:20:42.122702Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.126888Z","iopub.execute_input":"2021-08-03T07:20:42.127789Z","iopub.status.idle":"2021-08-03T07:20:42.142195Z","shell.execute_reply.started":"2021-08-03T07:20:42.127683Z","shell.execute_reply":"2021-08-03T07:20:42.140813Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# def train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5):\n#     # lowest_loss = np.inf #float(\"inf\")\n#     top_3_models = []\n#     for t in range(epochs):\n#         print(f\"Epoch {t+1}\\n-------------------------------\")\n# #         if device == \"cuda\":\n# #             train_loop_amp(train_loader, model, loss_function, optimizer)\n# #         else:\n# #             train_loop(train_loader, model, loss_function, optimizer)\n\n\n#         train_loop(train_loader, model, loss_function, optimizer)\n#         test_loss = test_loop(test_loader, model, loss_function)\n        \n#         # saving model checkpoint\n#         checkpoint = {\"epoch\": t+1, \n#                       \"model_state\": model.state_dict(), \n#                       \"optimizer_state\": optimizer.state_dict(),\n#                       \"scheduler_state\": scheduler.state_dict(), \n#                       \"loss\": test_loss}\n        \n#         if len(top_3_models) == 0:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n        \n#         if test_loss < top_3_models[0][\"loss\"]:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n\n#         if len(top_3_models) > 3:\n#             file_to_remove = top_3_models[0][\"filename\"]\n#             os.remove(file_to_remove)\n#             top_3_models.pop(0)\n\n#         # sort in descending order by loss \n#         top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n#         # print(f\"top_3_models length: {len(top_3_models)}\")\n            \n#     print(\"Done!\")\n    \n#     return model\n\n\ndef train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5, epochs_pretrained=0):\n    # lowest_loss = np.inf #float(\"inf\")\n    top_3_models = []\n    for t in range(epochs):\n        print(f\"Epoch {t+1}[{epochs_pretrained+t+1} in total]\\n-------------------------------\")\n#         if device == \"cuda\":\n#             train_loop_amp(train_loader, model, loss_function, optimizer)\n#         else:\n#             train_loop(train_loader, model, loss_function, optimizer)\n\n\n        train_loop(train_loader, model, loss_function, optimizer)\n        test_loss, test_auc = test_loop(test_loader, model, loss_function)\n        \n#         scheduler.step(test_auc)\n        scheduler.step(test_loss)\n        # saving model checkpoint\n        checkpoint = {\"epoch\": epochs_pretrained+t+1, \n                      \"model_state\": model.state_dict(), \n                      \"optimizer_state\": optimizer.state_dict(),\n                      \"scheduler_state\": scheduler.state_dict(), \n                      \"loss\": test_loss, \n                      \"auc\": test_auc}\n        \n        save_location = f\"./EfficientNet_b0_checkpoint_epoch_{epochs_pretrained+t+1}.pt\"\n        \n        # always save on first epoch\n        if len(top_3_models) == 0:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # save if loss is lower than highest/worst loss of saved models\n        if test_loss < top_3_models[0][\"loss\"]:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # removes worst performing model, but only if there are 3 or more models already saved\n        # keeps the 3 best models(measured by loss on validation set)\n        if len(top_3_models) > 3:\n            file_to_remove = top_3_models[0][\"filename\"]\n            os.remove(file_to_remove)\n            top_3_models.pop(0)\n\n        # sort in descending order by loss \n        top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n        # print(f\"top_3_models length: {len(top_3_models)}\")\n        \n        # always save last epoch\n        if t == epochs-1:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n            \n    print(\"Done!\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.144418Z","iopub.execute_input":"2021-08-03T07:20:42.144948Z","iopub.status.idle":"2021-08-03T07:20:42.160692Z","shell.execute_reply.started":"2021-08-03T07:20:42.144890Z","shell.execute_reply":"2021-08-03T07:20:42.158863Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, train_loader, test_loader, loss_function, optimizer, \n                    epochs=30, epochs_pretrained=0) #state_dict[\"epoch\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:20:42.162751Z","iopub.execute_input":"2021-08-03T07:20:42.163674Z","iopub.status.idle":"2021-08-03T08:58:01.432293Z","shell.execute_reply.started":"2021-08-03T07:20:42.163630Z","shell.execute_reply":"2021-08-03T08:58:01.430963Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1[1 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00032054534681768816, AUC = 0.8105666648796441 \n\nEpoch 2[2 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00036274167067274887, AUC = 0.8222359227291409 \n\nEpoch 3[3 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0003407425754539131, AUC = 0.8397844850694258 \n\nEpoch 4[4 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00036496701719193814, AUC = 0.8262611912292928 \n\nEpoch 5[5 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0003379522689269311, AUC = 0.8410577387015494 \n\nEpoch 6[6 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002552901995962853, AUC = 0.8347808216730106 \n\nEpoch 7[7 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002509307868524581, AUC = 0.8501894244000072 \n\nEpoch 8[8 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00024005681233592454, AUC = 0.8450606694186815 \n\nEpoch 9[9 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00024731058026912744, AUC = 0.8409817902392823 \n\nEpoch 10[10 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002469246115770507, AUC = 0.8392126378241214 \n\nEpoch 11[11 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002123924194889381, AUC = 0.8423577976732965 \n\nEpoch 12[12 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0001998356254779785, AUC = 0.8456191139941742 \n\nEpoch 13[13 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00022355345612767958, AUC = 0.8220438177951714 \n\nEpoch 14[14 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00024035246916274955, AUC = 0.8320332743615863 \n\nEpoch 15[15 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00021829604574049344, AUC = 0.8417457424185565 \n\nEpoch 16[16 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002225579046232442, AUC = 0.8391098840222305 \n\nEpoch 17[17 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.000192969544671775, AUC = 0.8357770867956897 \n\nEpoch 18[18 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00021380471437269923, AUC = 0.831117425257778 \n\nEpoch 19[19 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00020322708512518365, AUC = 0.8251174967386838 \n\nEpoch 20[20 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00019338344067218187, AUC = 0.822298468521596 \n\nEpoch 21[21 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00020399872059552934, AUC = 0.8178979252667131 \n\nEpoch 22[22 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.000200056458561668, AUC = 0.8279365249557713 \n\nEpoch 23[23 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002177680821213933, AUC = 0.8243401418895977 \n\nEpoch 24[24 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002070361995153689, AUC = 0.8263058667953324 \n\nEpoch 25[25 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00019165318135431876, AUC = 0.8236655408424025 \n\nEpoch 26[26 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.000197080430627283, AUC = 0.833288657767294 \n\nEpoch 27[27 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002121105160448366, AUC = 0.8194213620686573 \n\nEpoch 28[28 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.0002119493151548547, AUC = 0.8219053235404492 \n\nEpoch 29[29 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00020501542237097857, AUC = 0.8164057613609965 \n\nEpoch 30[30 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 96\nBatch number: 311/311\n\nAvg loss: 0.00019679457334919058, AUC = 0.8265962579745886 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"# def get_predictions(dataloader, model):\n#     predictions = []\n#     model.eval()\n\n#     with torch.no_grad():\n#         for X, y in dataloader:\n#             X = X.to(device=device)\n#             pred = model(X)\n#             for value in pred:\n#                 predictions.append(value.cpu().numpy()[0])\n            \n#     return predictions\n\n# def predict_multiple_epochs(dataloader, model, epochs=1):\n#     # Note: must use dataloader with batch_size=1\n#     predictions = np.zeros(len(dataloader.dataset))\n#     model.eval()\n    \n#     for i in range(epochs):\n#         j = 0\n#         with torch.no_grad():\n#             for X, y in dataloader:\n#                 X = X.to(device=device)\n#                 pred = model(X)\n#                 predictions[j] += pred[0][0].cpu().numpy()\n#                 j += 1\n\n#         print(f\"Epoch: {i+1}\")\n        \n#     predictions = predictions * (1.0/epochs)\n            \n#     return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-03T08:59:13.040885Z","iopub.execute_input":"2021-08-03T08:59:13.041312Z","iopub.status.idle":"2021-08-03T08:59:13.048431Z","shell.execute_reply.started":"2021-08-03T08:59:13.041276Z","shell.execute_reply":"2021-08-03T08:59:13.046807Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    predictions = []\n    targets = []\n    model.eval()\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X = X.to(device=device)\n            pred = model(X)\n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel()\n            \n    return predictions, targets\n\n\ndef predict_multiple_epochs(dataloader, model, epochs=1):\n    # Note: must use dataloader with batch_size=1\n    predictions = []\n    targets = []\n    model.eval()\n    \n    for i in range(epochs):\n        print(f\"Epoch: {i+1}\")\n        pred, targ = get_predictions(dataloader, model)\n        predictions.append(pred)\n        if i == 0:\n            targets.append(targ)\n            \n    targets = np.array(targets).ravel()\n    predictions = np.mean(predictions, axis=0)\n\n    return predictions, targets","metadata":{"execution":{"iopub.status.busy":"2021-08-03T08:59:16.496732Z","iopub.execute_input":"2021-08-03T08:59:16.497134Z","iopub.status.idle":"2021-08-03T08:59:16.508979Z","shell.execute_reply.started":"2021-08-03T08:59:16.497102Z","shell.execute_reply":"2021-08-03T08:59:16.507341Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Reset test loader with batch_size=1\n# so that we can use our predict_multiple_epochs function\n# to perform test-time augmentation\n# test_loader_new = DataLoader(dataset=test_ds, batch_size=1, \n#                              num_workers=1, pin_memory=True, shuffle=False)\n\ndef predict_multiple_epochs_TWO(test_df, model, epochs=1):\n    # Note: must use dataloader with batch_size=1\n    predictions = []\n    targets = []\n    model.eval()\n    \n    for i in range(epochs):\n        print(f\"Epoch: {i+1}\")\n        \n        test_ds_new = Melanoma_Dataset(test_df, root_dir=root_directory, transform=test_transforms) #image_transforms)\n        test_loader_new = DataLoader(dataset=test_ds_new, batch_size=1, num_workers=1, pin_memory=True, shuffle=False)\n        \n        pred, targ = get_predictions(test_loader_new, model)\n        predictions.append(pred)\n        if i == 0:\n            targets.append(targ)\n            \n    targets = np.array(targets).ravel()\n    predictions = np.mean(predictions, axis=0)\n\n    return predictions, targets\n# test_ds_new = Melanoma_Dataset(test_df, root_dir=root_directory, transform=image_transforms)\n# test_loader_new = DataLoader(dataset=test_ds, batch_size=1, \n#                          num_workers=1, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T08:59:21.472631Z","iopub.execute_input":"2021-08-03T08:59:21.473259Z","iopub.status.idle":"2021-08-03T08:59:21.485995Z","shell.execute_reply.started":"2021-08-03T08:59:21.473201Z","shell.execute_reply":"2021-08-03T08:59:21.483534Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# predictions, targets = predict_multiple_epochs(test_loader_new, model, epochs=1)\n# predictions = get_predictions(test_loader, model)\n\npredictions, targets = predict_multiple_epochs_TWO(test_df, model, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T08:59:27.555998Z","iopub.execute_input":"2021-08-03T08:59:27.556388Z","iopub.status.idle":"2021-08-03T09:09:37.175775Z","shell.execute_reply.started":"2021-08-03T08:59:27.556356Z","shell.execute_reply":"2021-08-03T09:09:37.174243Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch: 1\nEpoch: 2\nEpoch: 3\nEpoch: 4\nEpoch: 5\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"AUC: {sklearn.metrics.roc_auc_score(targets, predictions)}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:09:43.125049Z","iopub.execute_input":"2021-08-03T09:09:43.125446Z","iopub.status.idle":"2021-08-03T09:09:43.138433Z","shell.execute_reply.started":"2021-08-03T09:09:43.125407Z","shell.execute_reply":"2021-08-03T09:09:43.137150Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"AUC: 0.8216685430404405\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.hist(predictions, bins=20) #, range=(0,1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:09:46.523675Z","iopub.execute_input":"2021-08-03T09:09:46.524089Z","iopub.status.idle":"2021-08-03T09:09:46.758797Z","shell.execute_reply.started":"2021-08-03T09:09:46.524055Z","shell.execute_reply":"2021-08-03T09:09:46.757368Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"filtered_predictions = []\nfor pred in predictions:\n    if pred < 0:\n        filtered_predictions.append(0)\n    else:\n        filtered_predictions.append(1)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:09:55.081914Z","iopub.execute_input":"2021-08-03T09:09:55.082319Z","iopub.status.idle":"2021-08-03T09:09:55.101401Z","shell.execute_reply.started":"2021-08-03T09:09:55.082284Z","shell.execute_reply":"2021-08-03T09:09:55.099507Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"test_labels = test_df[\"target\"].values","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:10:03.383130Z","iopub.execute_input":"2021-08-03T09:10:03.383551Z","iopub.status.idle":"2021-08-03T09:10:03.388755Z","shell.execute_reply.started":"2021-08-03T09:10:03.383510Z","shell.execute_reply":"2021-08-03T09:10:03.387472Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_labels, filtered_predictions))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:10:06.528050Z","iopub.execute_input":"2021-08-03T09:10:06.528461Z","iopub.status.idle":"2021-08-03T09:10:06.549610Z","shell.execute_reply.started":"2021-08-03T09:10:06.528428Z","shell.execute_reply":"2021-08-03T09:10:06.548124Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.85      0.92      3244\n           1       0.08      0.59      0.14        69\n\n    accuracy                           0.85      3313\n   macro avg       0.53      0.72      0.53      3313\nweighted avg       0.97      0.85      0.90      3313\n\n","output_type":"stream"}]},{"cell_type":"code","source":"conf_matrix = confusion_matrix(test_labels, filtered_predictions)\n\nplt.figure(figsize=(14,7))\nsns.heatmap(conf_matrix, annot=True, cbar=True, cmap='Blues', fmt='g')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:10:36.945893Z","iopub.execute_input":"2021-08-03T09:10:36.946261Z","iopub.status.idle":"2021-08-03T09:10:37.283151Z","shell.execute_reply.started":"2021-08-03T09:10:36.946228Z","shell.execute_reply":"2021-08-03T09:10:37.281971Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Confusion Matrix')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x504 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# Predicting on the Test set","metadata":{}},{"cell_type":"code","source":"testing_df = pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Dataset class: Test set doesn't have a target\nclass Melanoma_Test_Dataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.annotations = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        length = self.annotations.shape[0]\n        return length\n    \n    def __getitem__(self, idx):\n        image_name = self.annotations[\"image_name\"].iloc[idx]\n        image_path = self.root_dir + \"/\" + image_name + \".jpg\"\n        image = img.imread(image_path)\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_directory = \"../input/siimisic-resized-224x224-jpeg/output_test/test\"\n\n\n# # test_ds_new = Melanoma_Test_Dataset(testing_df, root_dir=root_directory, transform=image_transforms) #image_transforms)\n# # test_loader_new = DataLoader(dataset=test_ds_new, batch_size=1, num_workers=1, pin_memory=True, shuffle=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions_2(dataloader, model):\n    predictions = []\n    #targets = []\n    model.eval()\n\n    with torch.no_grad():\n        for X in dataloader:\n            X = X.to(device=device)\n            pred = model(X)\n            predictions.append(pred.cpu())\n            #targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    #targets = np.vstack(targets).ravel()\n            \n    return predictions\n\ndef predict_multiple_epochs_2(test_df, model, epochs=1):\n    # Note: must use dataloader with batch_size=1\n    predictions = []\n    #targets = []\n    model.eval()\n    \n    for i in range(epochs):\n        print(f\"Epoch: {i+1}\")\n        \n        test_ds_new = Melanoma_Test_Dataset(test_df, root_dir=root_directory, transform=image_transforms) #image_transforms)\n        test_loader_new = DataLoader(dataset=test_ds_new, batch_size=1, num_workers=1, pin_memory=True, shuffle=False)\n        \n        pred = get_predictions_2(test_loader_new, model)\n        predictions.append(pred)\n#         if i == 0:\n#             targets.append(targ)\n            \n    # targets = np.array(targets).ravel()\n    predictions = np.mean(predictions, axis=0)\n\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # predictions = predict_multiple_epochs_2(test_loader_new, model, epochs=10)\npredictions = predict_multiple_epochs_2(testing_df, model, epochs=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_tensor = torch.Tensor(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = torch.sigmoid(pred_tensor)\n\npred = pred.cpu().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(pred, bins=20) #, range=(0,1))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_df[\"target\"] = pred\nsubmission_df = testing_df[[\"image_name\", \"target\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"efficientnetb4_model_predictions.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}