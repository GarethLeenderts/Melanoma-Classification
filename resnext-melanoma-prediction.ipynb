{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T17:08:46.487755Z","iopub.execute_input":"2021-08-04T17:08:46.488122Z","iopub.status.idle":"2021-08-04T17:08:46.496500Z","shell.execute_reply.started":"2021-08-04T17:08:46.488041Z","shell.execute_reply":"2021-08-04T17:08:46.495693Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Process\n\n* Set imports\n* Define model architecture\n* set device(GPU or CPU)\n* Define hyperparameters\n* Create your(custom) Dataset(inherits from the Dataset class)\n    * Define DataSets\n    * Define DataLoaders\n* initialize/instantiate network\n* Compile model\n    * Define loss\n    * Define optimizer\n* Train the network (create training for loop)\n    set model to training mode? model.train()?\n    * for epochs\n        * for batch, features, labels in DataLoader\n            * set data to the device(import for cuda, ie. gpu enabled)\n            * Forward pass: predictions and loss\n            * Backward pass: optimizer.zero_grad() & loss.backward()\n            * Gradient descent: optimizer.step()\n* Define testing/validation loop\n    * remember: set model to evaluation mode(with torch.zero_grad??? or model.eval()???)\n    \n\n* Data Augmentation (extra step for image data)\n    * Done with PyTorch Transforms\n    * `import torchvision.transforms as transforms`\n    * `my_transforms = transforms.Compose([your list of transformations go here])`\n    * tranforms get implemented in datasets when you include them in the `transforms` argument of the dataset","metadata":{}},{"cell_type":"code","source":"# imports\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom tqdm import tqdm  \nimport torchvision.transforms as transforms\n\nimport matplotlib.image as img\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:46.501008Z","iopub.execute_input":"2021-08-04T17:08:46.501513Z","iopub.status.idle":"2021-08-04T17:08:48.772234Z","shell.execute_reply.started":"2021-08-04T17:08:46.501475Z","shell.execute_reply":"2021-08-04T17:08:48.771356Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nlearning_rate = 0.001 #3e-4 #0.001\nbatch_size = 80 #48 #16 #32 #64 #80","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:48.773816Z","iopub.execute_input":"2021-08-04T17:08:48.774152Z","iopub.status.idle":"2021-08-04T17:08:48.784084Z","shell.execute_reply.started":"2021-08-04T17:08:48.774114Z","shell.execute_reply":"2021-08-04T17:08:48.781141Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:48.788697Z","iopub.execute_input":"2021-08-04T17:08:48.789472Z","iopub.status.idle":"2021-08-04T17:08:48.929890Z","shell.execute_reply.started":"2021-08-04T17:08:48.789424Z","shell.execute_reply":"2021-08-04T17:08:48.927550Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:48.931829Z","iopub.execute_input":"2021-08-04T17:08:48.932366Z","iopub.status.idle":"2021-08-04T17:08:48.975119Z","shell.execute_reply.started":"2021-08-04T17:08:48.932320Z","shell.execute_reply":"2021-08-04T17:08:48.974257Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df = df[[\"image_name\",\"target\"]].sample(3000, random_state=125)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:48.979663Z","iopub.execute_input":"2021-08-04T17:08:48.982077Z","iopub.status.idle":"2021-08-04T17:08:48.988143Z","shell.execute_reply.started":"2021-08-04T17:08:48.982024Z","shell.execute_reply":"2021-08-04T17:08:48.987046Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# df[[\"image_name\",\"target\"]][df[\"target\"] == 1].info()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:48.991958Z","iopub.execute_input":"2021-08-04T17:08:48.993907Z","iopub.status.idle":"2021-08-04T17:08:49.002236Z","shell.execute_reply.started":"2021-08-04T17:08:48.993860Z","shell.execute_reply":"2021-08-04T17:08:49.000884Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Dataset\nclass Melanoma_Dataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.annotations = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        length = self.annotations.shape[0]\n        return length\n    \n    def __getitem__(self, idx):\n        image_name = self.annotations[\"image_name\"].iloc[idx]\n        target = self.annotations[\"target\"].iloc[idx]\n        image_path = self.root_dir + \"/\" + image_name + \".jpg\"\n        image = img.imread(image_path)\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        \n        target = torch.tensor([target], dtype=torch.float32)\n            \n        return image, target","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:49.005266Z","iopub.execute_input":"2021-08-04T17:08:49.006573Z","iopub.status.idle":"2021-08-04T17:08:49.023261Z","shell.execute_reply.started":"2021-08-04T17:08:49.006508Z","shell.execute_reply":"2021-08-04T17:08:49.021636Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#VGG16 model\n\n# base_model_resnext50 = torchvision.models.resnext50_32x4d(pretrained=True)\n# torch.save(base_model_resnext50, \"./resnext50_32x4d.pt\") # saves to \"output\"\n\nbase_model_resnext50 = torch.load(\"../input/siimmelanomatrainedmodels/resnext50_32x4d.pt\")\n\n\n# base_model_resnext101 = torchvision.models.resnext101_32x8d(pretrained=True)\n# torch.save(base_model_resnext101, \"./resnext101_32x8d.pt\") # saves to \"output\"\n\n# base_model_resnext101 = torch.load(\"./resnext101_32x8d.pt\")\n\n\n# print(base_model)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:49.030840Z","iopub.execute_input":"2021-08-04T17:08:49.033746Z","iopub.status.idle":"2021-08-04T17:08:51.238539Z","shell.execute_reply.started":"2021-08-04T17:08:49.033696Z","shell.execute_reply":"2021-08-04T17:08:51.237706Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# print(base_model)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.240543Z","iopub.execute_input":"2021-08-04T17:08:51.240900Z","iopub.status.idle":"2021-08-04T17:08:51.245105Z","shell.execute_reply.started":"2021-08-04T17:08:51.240864Z","shell.execute_reply":"2021-08-04T17:08:51.244072Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# print(base_model)\n\nclass ResNext50_base(nn.Module):\n    def __init__(self, base_trainable=False):\n        super(ResNext50_base, self).__init__()\n        \n        self.resnext50_base = base_model_resnext50\n        \n        for param in self.resnext50_base.parameters():\n            param.requires_grad = base_trainable\n        \n        self.fc1 = nn.Linear(1000, 1000)\n        self.fc2 = nn.Linear(1000, 1000)\n        self.fc3 = nn.Linear(1000, 750)\n        self.fc4 = nn.Linear(750, 500)\n        self.fc5 = nn.Linear(500, 100)\n        self.fc6 = nn.Linear(100, 1)\n        \n    def forward(self, x):\n        x = self.resnext50_base(x)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))\n        x = torch.relu(self.fc4(x))\n        x = torch.relu(self.fc5(x))\n        x = self.fc6(x)\n        return x\n\n\n\n# class ResNext101_base(nn.Module):\n#     def __init__(self, base_trainable=False):\n#         super(ResNext101_base, self).__init__()\n        \n#         self.resnext101_base = base_model_resnext101\n        \n#         for param in self.resnext101_base.parameters():\n#             param.requires_grad = base_trainable\n        \n#         self.fc1 = nn.Linear(1000, 1000)\n#         self.fc2 = nn.Linear(1000, 1000)\n#         self.fc3 = nn.Linear(1000, 750)\n#         self.fc4 = nn.Linear(750, 500)\n#         self.fc5 = nn.Linear(500, 100)\n#         self.fc6 = nn.Linear(100, 1)\n        \n#     def forward(self, x):\n#         x = self.resnext101_base(x)\n#         x = torch.relu(self.fc1(x))\n#         x = torch.relu(self.fc2(x))\n#         x = torch.relu(self.fc3(x))\n#         x = torch.relu(self.fc4(x))\n#         x = torch.relu(self.fc5(x))\n#         x = self.fc6(x)\n#         return x","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.246677Z","iopub.execute_input":"2021-08-04T17:08:51.247134Z","iopub.status.idle":"2021-08-04T17:08:51.260524Z","shell.execute_reply.started":"2021-08-04T17:08:51.247095Z","shell.execute_reply":"2021-08-04T17:08:51.259630Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.261845Z","iopub.execute_input":"2021-08-04T17:08:51.262189Z","iopub.status.idle":"2021-08-04T17:08:51.338489Z","shell.execute_reply.started":"2021-08-04T17:08:51.262153Z","shell.execute_reply":"2021-08-04T17:08:51.337565Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# augmentations/transforms\nimages_mean = (0.8060590931711208, 0.620982283291032, 0.5915027590675953)\nimages_std = (0.08131081913267031, 0.09455098010432171, 0.10589780296354254)\nimage_transforms = transforms.Compose(\n    [  # Compose makes it possible to have many transforms\n        transforms.ToPILImage(),\n        transforms.RandomRotation(degrees=90),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.ToTensor(), # Note: ToTensor() actually scales pixel values between 0 and 1\n        transforms.Normalize(mean=images_mean, std=images_std),\n    ]\n)\n\n\ntest_transforms = transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=images_mean, std=images_std),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.342387Z","iopub.execute_input":"2021-08-04T17:08:51.342662Z","iopub.status.idle":"2021-08-04T17:08:51.351476Z","shell.execute_reply.started":"2021-08-04T17:08:51.342631Z","shell.execute_reply":"2021-08-04T17:08:51.350581Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.1) #, random_state=125)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.354635Z","iopub.execute_input":"2021-08-04T17:08:51.354895Z","iopub.status.idle":"2021-08-04T17:08:51.372400Z","shell.execute_reply.started":"2021-08-04T17:08:51.354871Z","shell.execute_reply":"2021-08-04T17:08:51.371625Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"total_samples = len(train_df[\"target\"])\nclass_1_count = sum(train_df[\"target\"]) + 0.0001 #in case class_1_count is zero\nclass_0_count = total_samples - class_1_count\nclass_weights = [total_samples/class_0_count, total_samples/class_1_count]\n\nlist_of_weights = [class_weights[i] for i in train_df[\"target\"]]\nweighted_sampler = WeightedRandomSampler(list_of_weights, num_samples = len(list_of_weights), replacement=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.373687Z","iopub.execute_input":"2021-08-04T17:08:51.374061Z","iopub.status.idle":"2021-08-04T17:08:51.394333Z","shell.execute_reply.started":"2021-08-04T17:08:51.374023Z","shell.execute_reply":"2021-08-04T17:08:51.393373Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # Instantiate Datasets and DataLoaders\n# # root_directory = \"../input/siim-isic-melanoma-classification/jpeg/train\"\nroot_directory = \"../input/siimisic-resized-224x224-jpeg/output_train/train\"\n\ntrain_ds = Melanoma_Dataset(train_df, root_dir=root_directory, transform=image_transforms)\ntest_ds = Melanoma_Dataset(test_df, root_dir=root_directory, transform=image_transforms)\n\ntrain_loader = DataLoader(dataset=train_ds, batch_size=batch_size, sampler=weighted_sampler,\n                          num_workers=1, pin_memory=True)#, shuffle=True) #set shuffle=True\ntest_loader = DataLoader(dataset=test_ds, batch_size=batch_size, \n                         num_workers=1, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.395829Z","iopub.execute_input":"2021-08-04T17:08:51.396189Z","iopub.status.idle":"2021-08-04T17:08:51.404944Z","shell.execute_reply.started":"2021-08-04T17:08:51.396152Z","shell.execute_reply":"2021-08-04T17:08:51.403950Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# # find mean and std deviation of images for transforms.Normalize()\n# def compute_mean_and_std(dataloader):\n#     count = 0\n#     mean_1 = 0\n#     mean_2 = 0\n#     mean_3 = 0\n#     std_1 = 0\n#     std_2 = 0\n#     std_3 = 0\n#     for batch, (X, y) in enumerate(dataloader):\n\n#         X = X.to(device=device)\n\n#         for image in X:\n#             mean_1 += torch.mean(image[0]).item() # .item() converts 'tensor(0.005)' to '0.005'\n#             mean_2 += torch.mean(image[1]).item()\n#             mean_3 += torch.mean(image[2]).item()\n#             std_1 += torch.std(image[0]).item()\n#             std_2 += torch.std(image[1]).item()\n#             std_3 += torch.std(image[2]).item()\n\n#             count += 1\n#             print(count, end=\"\\r\")\n    \n#     mean_final = (mean_1/count, mean_2/count, mean_3/count)\n#     std_final = (std_1/count, std_2/count, std_3/count)\n    \n#     return mean_final, std_final","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.406665Z","iopub.execute_input":"2021-08-04T17:08:51.407148Z","iopub.status.idle":"2021-08-04T17:08:51.414088Z","shell.execute_reply.started":"2021-08-04T17:08:51.407097Z","shell.execute_reply":"2021-08-04T17:08:51.413307Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# mean_, std_ = compute_mean_and_std(train_loader)\n\n# print(mean_, std_)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.415338Z","iopub.execute_input":"2021-08-04T17:08:51.415728Z","iopub.status.idle":"2021-08-04T17:08:51.425736Z","shell.execute_reply.started":"2021-08-04T17:08:51.415695Z","shell.execute_reply":"2021-08-04T17:08:51.424915Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Instantiate network\n\nmodel = ResNext50_base(base_trainable=True).to(device)\n# model = ResNext101_base(base_trainable=True).to(device)\n# model = torch.load(\"./ResNext101_trained_5_epochs.pt\")\n\n\n# model_checkpoint = torch.load(\"../input/siimmelanomatrainedmodels/resnext50_model_checkpoint_epoch_39.pt\", \n#                               map_location=device)\n# model = ResNext50_base(base_trainable=True).to(device)\n# model_state_dict = model_checkpoint[\"model_state\"]\n# model.load_state_dict(model_state_dict)\n# model = model.to(device)\n\n# using a model state_dict\n# model_state_dict = torch.load(\"path-to-state_dict\", \n#                               map_location=device)\n# model.load_state_dict(model_state_dict)\n# model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:51.427066Z","iopub.execute_input":"2021-08-04T17:08:51.427535Z","iopub.status.idle":"2021-08-04T17:08:55.853536Z","shell.execute_reply.started":"2021-08-04T17:08:51.427499Z","shell.execute_reply":"2021-08-04T17:08:55.852584Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# model_checkpoint[\"scheduler_state\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.855679Z","iopub.execute_input":"2021-08-04T17:08:55.856346Z","iopub.status.idle":"2021-08-04T17:08:55.860551Z","shell.execute_reply.started":"2021-08-04T17:08:55.856303Z","shell.execute_reply":"2021-08-04T17:08:55.859493Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Focal Loss Function\n# from this blog post: https://amaarora.github.io/2020/06/29/FocalLoss.html\n\nclass WeightedFocalLoss(nn.Module):\n    \"Non weighted version of Focal Loss\"\n    def __init__(self, alpha=.25, gamma=2):\n        super(WeightedFocalLoss, self).__init__()\n        self.alpha = torch.tensor([alpha, 1-alpha]).to(device)  #.cuda() #remember to define \"device\"\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        targets = targets.type(torch.long)\n        at = self.alpha.gather(0, targets.data.view(-1))\n        pt = torch.exp(-BCE_loss)\n        F_loss = at*(1-pt)**self.gamma * BCE_loss\n        return F_loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.862110Z","iopub.execute_input":"2021-08-04T17:08:55.862520Z","iopub.status.idle":"2021-08-04T17:08:55.875069Z","shell.execute_reply.started":"2021-08-04T17:08:55.862460Z","shell.execute_reply":"2021-08-04T17:08:55.874241Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\n# loss_function = nn.BCEWithLogitsLoss()\nloss_function = WeightedFocalLoss(alpha=0.25, gamma=2.0)\n# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n\n# learning rate scheduler\n# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate, \n#                                               max_lr=0.1,step_size_up=5,mode=\"triangular2\")\n\n\n\n# from abishek thakur: https://www.kaggle.com/abhishek/melanoma-detection-with-pytorch?scriptVersionId=35193166\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                       patience=3, \n                                                       threshold=0.001, \n                                                       mode=\"min\"\n                                                      )\n\n# es = EarlyStopping(patience=5, mode=\"max\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.878305Z","iopub.execute_input":"2021-08-04T17:08:55.878547Z","iopub.status.idle":"2021-08-04T17:08:55.891111Z","shell.execute_reply.started":"2021-08-04T17:08:55.878524Z","shell.execute_reply":"2021-08-04T17:08:55.890158Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import math\n\n# # from documentation: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n#         scheduler.step(loss)\n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")\n\n\ndef test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    test_loss, correct = 0, 0\n    \n    model.eval()\n    \n    predictions = []\n    targets = []\n    with torch.no_grad():\n        for X, y in dataloader:\n            \n            X = X.to(device=device)\n            y = y.to(device=device)\n            \n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            \n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel() #test_df[\"target\"].values\n    auc = sklearn.metrics.roc_auc_score(targets, predictions)\n\n    test_loss /= size\n#     auc /= size\n    # print(f\"Avg loss: {test_loss:>8f} \\n\")\n    print(f\"Avg loss: {test_loss}, AUC = {auc} \\n\")\n    \n    return test_loss, auc","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.894474Z","iopub.execute_input":"2021-08-04T17:08:55.894929Z","iopub.status.idle":"2021-08-04T17:08:55.909632Z","shell.execute_reply.started":"2021-08-04T17:08:55.894893Z","shell.execute_reply":"2021-08-04T17:08:55.908654Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Training Loop with AMP(automatic mixed precision)\n\n# mixed precision scaler\nscaler = torch.cuda.amp.GradScaler()\n\ndef train_loop_amp(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    batch_size = dataloader.batch_size\n    print(f\"Total samples: {size}\")\n    print(f\"Batch size: {batch_size}\")\n    \n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        \n        X = X.to(device=device)\n        y = y.to(device=device)\n        \n        \n        # forward\n        with torch.cuda.amp.autocast():\n            pred = model(X)\n            loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        print(f\"Batch number: {batch+1}/{math.ceil(size/batch_size)}\", end=\"\\r\")\n    \n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.915425Z","iopub.execute_input":"2021-08-04T17:08:55.915780Z","iopub.status.idle":"2021-08-04T17:08:55.926504Z","shell.execute_reply.started":"2021-08-04T17:08:55.915748Z","shell.execute_reply":"2021-08-04T17:08:55.925561Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.928522Z","iopub.execute_input":"2021-08-04T17:08:55.928863Z","iopub.status.idle":"2021-08-04T17:08:55.939538Z","shell.execute_reply.started":"2021-08-04T17:08:55.928835Z","shell.execute_reply":"2021-08-04T17:08:55.938744Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# def train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5):\n#     # lowest_loss = np.inf #float(\"inf\")\n#     top_3_models = []\n#     for t in range(epochs):\n#         print(f\"Epoch {t+1}\\n-------------------------------\")\n# #         if device == \"cuda\":\n# #             train_loop_amp(train_loader, model, loss_function, optimizer)\n# #         else:\n# #             train_loop(train_loader, model, loss_function, optimizer)\n\n\n#         train_loop(train_loader, model, loss_function, optimizer)\n#         test_loss = test_loop(test_loader, model, loss_function)\n        \n#         # saving model checkpoint\n#         checkpoint = {\"epoch\": t+1, \n#                       \"model_state\": model.state_dict(), \n#                       \"optimizer_state\": optimizer.state_dict(),\n#                       \"scheduler_state\": scheduler.state_dict(), \n#                       \"loss\": test_loss}\n        \n#         if len(top_3_models) == 0:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n        \n#         if test_loss < top_3_models[0][\"loss\"]:\n#             torch.save(checkpoint, f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\")\n#             top_3_models.append({\"filename\": f\"./resnext50_model_checkpoint_epoch_{t+1}.pt\", \n#                                  \"loss\": test_loss})\n\n#         if len(top_3_models) > 3:\n#             file_to_remove = top_3_models[0][\"filename\"]\n#             os.remove(file_to_remove)\n#             top_3_models.pop(0)\n\n#         # sort in descending order by loss \n#         top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n#         # print(f\"top_3_models length: {len(top_3_models)}\")\n            \n#     print(\"Done!\")\n    \n#     return model\n\n\ndef train_model(model, train_loader, test_loader, loss_function, optimizer, epochs=5, epochs_pretrained=0):\n    # lowest_loss = np.inf #float(\"inf\")\n    top_3_models = []\n    for t in range(epochs):\n        print(f\"Epoch {t+1}[{epochs_pretrained+t+1} in total]\\n-------------------------------\")\n#         if device == \"cuda\":\n#             train_loop_amp(train_loader, model, loss_function, optimizer)\n#         else:\n#             train_loop(train_loader, model, loss_function, optimizer)\n\n\n        train_loop(train_loader, model, loss_function, optimizer)\n        test_loss, test_auc = test_loop(test_loader, model, loss_function)\n        \n        scheduler.step(test_loss)\n        # saving model checkpoint\n        checkpoint = {\"epoch\": epochs_pretrained+t+1, \n                      \"model_state\": model.state_dict(), \n                      \"optimizer_state\": optimizer.state_dict(),\n                      \"scheduler_state\": scheduler.state_dict(), \n                      \"loss\": test_loss, \n                      \"auc\": test_auc}\n        \n        save_location = f\"./resnext50_model_checkpoint_epoch_{epochs_pretrained+t+1}.pt\"\n#         save_location = f\"./resnext101_model_checkpoint_epoch_{epochs_pretrained+t+1}.pt\"\n        \n        # always save on first epoch\n        if len(top_3_models) == 0:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # save if loss is lower than highest/worst loss of saved models\n        if test_loss < top_3_models[0][\"loss\"]:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n        \n        # removes worst performing model, but only if there are 3 or more models already saved\n        # keeps the 3 best models(measured by loss on validation set)\n        if len(top_3_models) > 3:\n            file_to_remove = top_3_models[0][\"filename\"]\n            os.remove(file_to_remove)\n            top_3_models.pop(0)\n\n        # sort in descending order by loss \n        top_3_models = sorted(top_3_models, key=lambda k: k[\"loss\"], reverse=True)\n            \n        # print(f\"top_3_models length: {len(top_3_models)}\")\n        \n        # always save last epoch\n        if t == epochs-1:\n            torch.save(checkpoint, save_location)\n            top_3_models.append({\"filename\": save_location, \n                                 \"loss\": test_loss})\n            \n    print(\"Done!\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.942590Z","iopub.execute_input":"2021-08-04T17:08:55.942895Z","iopub.status.idle":"2021-08-04T17:08:55.955346Z","shell.execute_reply.started":"2021-08-04T17:08:55.942871Z","shell.execute_reply":"2021-08-04T17:08:55.954479Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, train_loader, test_loader, loss_function, optimizer, \n                    epochs=10, epochs_pretrained=0) #model_checkpoint[\"epoch\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T17:08:55.957272Z","iopub.execute_input":"2021-08-04T17:08:55.957637Z","iopub.status.idle":"2021-08-04T18:35:05.135309Z","shell.execute_reply.started":"2021-08-04T17:08:55.957592Z","shell.execute_reply":"2021-08-04T18:35:05.134369Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1[1 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00019476667058915845, AUC = 0.8899771192588872 \n\nEpoch 2[2 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00016141310453678036, AUC = 0.8798761091578772 \n\nEpoch 3[3 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0001659120351756135, AUC = 0.8966850828729281 \n\nEpoch 4[4 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00016428288024558676, AUC = 0.8601484457838049 \n\nEpoch 5[5 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00012416946477518992, AUC = 0.8877615938389418 \n\nEpoch 6[6 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.0001434038858333647, AUC = 0.8704950053016351 \n\nEpoch 7[7 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00013552182514617967, AUC = 0.8847480328143311 \n\nEpoch 8[8 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00011280140376174999, AUC = 0.8870082035827892 \n\nEpoch 9[9 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00021278075206563227, AUC = 0.8753669289580891 \n\nEpoch 10[10 in total]\n-------------------------------\nTotal samples: 29813\nBatch size: 80\nBatch number: 373/373\n\nAvg loss: 0.00015274676493035364, AUC = 0.8629555220715441 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"# def get_predictions(dataloader, model):\n#     predictions = []\n#     model.eval()\n\n#     with torch.no_grad():\n#         for X, y in dataloader:\n#             X = X.to(device=device)\n#             pred = model(X)\n#             for value in pred:\n#                 predictions.append(value.cpu().numpy()[0])\n            \n#     return predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:35:05.136954Z","iopub.execute_input":"2021-08-04T18:35:05.137345Z","iopub.status.idle":"2021-08-04T18:35:05.143311Z","shell.execute_reply.started":"2021-08-04T18:35:05.137302Z","shell.execute_reply":"2021-08-04T18:35:05.142592Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def get_predictions(dataloader, model):\n    predictions = []\n    targets = []\n    model.eval()\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X = X.to(device=device)\n            pred = model(X)\n            predictions.append(pred.cpu())\n            targets.append(y.cpu())\n    \n    predictions = np.vstack(predictions).ravel()\n    targets = np.vstack(targets).ravel()\n            \n    return predictions, targets\n\n\ndef predict_multiple_epochs(dataloader, model, epochs=1):\n    # Note: must use dataloader with batch_size=1\n    predictions = []\n    targets = []\n    model.eval()\n    \n    for i in range(epochs):\n        print(f\"Epoch: {i+1}\")\n        pred, targ = get_predictions(dataloader, model)\n        predictions.append(pred)\n        if i == 0:\n            targets.append(targ)\n            \n    targets = np.array(targets).ravel()\n    predictions = np.mean(predictions, axis=0)\n\n    return predictions, targets","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:35:05.144552Z","iopub.execute_input":"2021-08-04T18:35:05.144959Z","iopub.status.idle":"2021-08-04T18:35:05.154394Z","shell.execute_reply.started":"2021-08-04T18:35:05.144922Z","shell.execute_reply":"2021-08-04T18:35:05.153533Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Reset test loader with batch_size=1\n# so that we can use our predict_multiple_epochs function\n# to perform test-time augmentation\ntest_loader_new = DataLoader(dataset=test_ds, batch_size=1, \n                             num_workers=1, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:35:05.155649Z","iopub.execute_input":"2021-08-04T18:35:05.156178Z","iopub.status.idle":"2021-08-04T18:35:05.167338Z","shell.execute_reply.started":"2021-08-04T18:35:05.156141Z","shell.execute_reply":"2021-08-04T18:35:05.166468Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"predictions, targets = predict_multiple_epochs(test_loader_new, model, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:43:27.360462Z","iopub.execute_input":"2021-08-04T18:43:27.360904Z","iopub.status.idle":"2021-08-04T19:09:53.034042Z","shell.execute_reply.started":"2021-08-04T18:43:27.360863Z","shell.execute_reply":"2021-08-04T19:09:53.033000Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch: 1\nEpoch: 2\nEpoch: 3\nEpoch: 4\nEpoch: 5\nEpoch: 6\nEpoch: 7\nEpoch: 8\nEpoch: 9\nEpoch: 10\nEpoch: 11\nEpoch: 12\nEpoch: 13\nEpoch: 14\nEpoch: 15\nEpoch: 16\nEpoch: 17\nEpoch: 18\nEpoch: 19\nEpoch: 20\n","output_type":"stream"}]},{"cell_type":"code","source":"# plt.subplot(1, 2, 1)\nplt.hist(predictions, bins=50) #, range=(0, 0.001))\nplt.show()\n\n# plt.subplot(1, 2, 2)\n# plt.hist(predictions_new, bins=20)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:09:53.035722Z","iopub.execute_input":"2021-08-04T19:09:53.036063Z","iopub.status.idle":"2021-08-04T19:09:53.268283Z","shell.execute_reply.started":"2021-08-04T19:09:53.036025Z","shell.execute_reply":"2021-08-04T19:09:53.267197Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"filtered_predictions = []\nfor pred in predictions:\n    if pred < 0:\n        filtered_predictions.append(0)\n    else:\n        filtered_predictions.append(1)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:09:53.270157Z","iopub.execute_input":"2021-08-04T19:09:53.270516Z","iopub.status.idle":"2021-08-04T19:09:53.288860Z","shell.execute_reply.started":"2021-08-04T19:09:53.270477Z","shell.execute_reply":"2021-08-04T19:09:53.287727Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"test_labels = test_df[\"target\"].values","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:09:53.290635Z","iopub.execute_input":"2021-08-04T19:09:53.291056Z","iopub.status.idle":"2021-08-04T19:09:53.300245Z","shell.execute_reply.started":"2021-08-04T19:09:53.291013Z","shell.execute_reply":"2021-08-04T19:09:53.299255Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_labels, filtered_predictions))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:09:53.301676Z","iopub.execute_input":"2021-08-04T19:09:53.302163Z","iopub.status.idle":"2021-08-04T19:09:53.322127Z","shell.execute_reply.started":"2021-08-04T19:09:53.302109Z","shell.execute_reply":"2021-08-04T19:09:53.321312Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      3258\n           1       0.20      0.22      0.21        55\n\n    accuracy                           0.97      3313\n   macro avg       0.60      0.60      0.60      3313\nweighted avg       0.97      0.97      0.97      3313\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sklearn.metrics.roc_auc_score(targets, predictions))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:09:53.323501Z","iopub.execute_input":"2021-08-04T19:09:53.323874Z","iopub.status.idle":"2021-08-04T19:09:53.332389Z","shell.execute_reply.started":"2021-08-04T19:09:53.323839Z","shell.execute_reply":"2021-08-04T19:09:53.331355Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"0.8622579385010324\n","output_type":"stream"}]},{"cell_type":"code","source":"conf_matrix = confusion_matrix(test_labels, filtered_predictions)\n\nplt.figure(figsize=(14,7))\nsns.heatmap(conf_matrix, annot=True, cbar=True, cmap='Blues', fmt='g')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T19:09:53.333879Z","iopub.execute_input":"2021-08-04T19:09:53.334300Z","iopub.status.idle":"2021-08-04T19:09:53.581556Z","shell.execute_reply.started":"2021-08-04T19:09:53.334265Z","shell.execute_reply":"2021-08-04T19:09:53.580782Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Confusion Matrix')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x504 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}